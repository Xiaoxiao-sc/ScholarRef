title,link,abstract
Introducing Peripheral Awareness as a Neurological State for Human-computer Integration,https://dl.acm.org/doi/10.1145/3313831.3376128,"
In this work we introduce peripheral awareness as a neurological state for real-time human-computer integration, where the human is assisted by a computer to interact with the world. Changes to the field of view in peripheral awareness have been linked with quality of human performance. This instinctive narrowing of vision that occurs as a threat is perceived has implications in activities that benefit from the user having a wide field of view, such as cycling to navigate the environment. We present ""Ena"", a novel EEG-eBike system that draws from the user's neural activity to determine when the user is in a state of peripheral awareness to regulate engine support. A study with 20 participants revealed various themes and tactics suggesting that peripheral awareness as a neurological state is viable to align human-machine integration with internal bodily processes. Ena suggests that our work facilitates a safe and enjoyable human-computer integration experience. Prior work in HCI has not yet studied changes to the user’s field of view in relation to peripheral awareness via the user’s neural activity. Peripheral awareness can influence how much we see, our thinking processes that hinder or support creativity, human performance and the resulting decisions we make. As such, this link between peripheral awareness and our interactions with the world is of paramount importance to the HCI community. To take the first steps to begin filling this gap in knowledge and further our field, we orchestrated and studied a system outside of the lab, in a real world setting, using peripheral awareness as neurological state via EEG in real-time—the changes in the user’s field of view were used to create an integration between the user and an electric bike, which regulated engine support according to whether or not the user was in a state of peripheral awareness. By drawing directly from the user’s neurological activity while navigating the environment, our system was able to access and react to the user’s pre-attentive processing state to support the user experience. In this first-of-a-kind approach in HCI, we offer a detailed system implementation description, including reusable code, practical themes and tactics resulting from a study with 20 bike riders to study and design integration experiences that use peripheral awareness as a neurological state. Potential future work includes an invitation for the field to explore aligning interactive experiences with internal bodily processes, such as peripheral awareness, to inform, design and afford a greater benefit to people.
"
Venous Materials: Towards Interactive Fluidic Mechanisms,https://dl.acm.org/doi/10.1145/3313831.3376129,"
Venous Materials is a novel concept and approach of an interactive material utilizing fluidic channels. We present a design method for fluidic mechanisms that respond to deformation by mechanical inputs from the user, such as pressure and bending. We designed a set of primitive venous structures that act as embedded analog fluidic sensors, displaying flow and color change. In this paper, we consider the fluid as the medium to drive tangible information triggered by deformation, and at the same time, to function as a responsive display of that information. To provide users with a simple way to create and validate designs of fluidic structures, we built a software platform and design tool UI. This design tool allows users to quickly design the geometry, and simulate the flow with intended mechanical force dynamically. We present a range of applications that demonstrate how Venous Materials can be utilized to augment interactivity of everyday physical objects. In conclusion, our paper introduced Venous Materials, a new category of interactive material that utilizes internal fluidic mechanisms that respond to deformation input and displays information by flow of liquid. We presented the design space to define the versatile capability of our approach together with a design pipeline including simulation software and an accessible laser-cutter-based fabrication method. Our technical evaluation validated that the simulation results match the behavior of our actual fabricated samples with simple geometric patterns. While there are many future challenges and design opportunities, the exploration of Venous Materials in this paper opens a channel towards the rich potential interaction capabilities of fluidic mechanisms.

"
Considering Parents in Coding Kit Design: Understanding Parents' Perspectives and Roles,https://dl.acm.org/doi/10.1145/3313831.3376130,"
As education researchers, policymakers, and industry leaders recognize the importance of computing, many coding kits (toys and apps) have emerged to help young children learn to code at home. However, how parents perceive and support their children's use of the kits at home are less understood. In this study, we performed semi-structured interviews with eighteen parents who obtained coding kits for their young children for home use. The results show parents expected their kids to have fun and meaningful interactions with the kits. In supporting the play, parents took on various roles, mostly acting as spectator, scaffolder, and teacher. While parents perceived benefits of coding kits like a changed perspective on coding, they also reported concerns, such as their limited programming knowledge to provide help. Finally, we reflect on design and research implications to develop coding kits that consider parents' perspectives and important roles in supporting young children's exploration with computational thinking. In this study, we performed semi-structured interviews with eighteen parents whose young child(ren) had experiences with coding kit(s) at home. The findings provide insights into parents’ expectations, roles, perceived benefits, and concerns around their children’s learning and play with coding kits. In supporting children’s interaction with the kits, parents took on various roles, mostly acting as spectators, scaffolders, and teachers. Some new roles were also identified, such as being an enforcer, executor, and dominator. We further reflect on implications for coding kit design based on parents’ perspectives and roles, such as including design features to support parents’ roles and sibling play. This work not only expands the understanding of parent-child interaction in children’s use of educational technologies but also can inspire coding kit designs that consider the important roles and perspectives of parents to better support children’s exploration with computational thinking.
"
"If I Hear You Correctly: Building and Evaluating Interview Chatbots with Active Listening
                                 Skills",https://dl.acm.org/doi/10.1145/3313831.3376131,"
Interview chatbots engage users in a text-based conversation to draw out their views and opinions. It is, however, challenging to build effective interview chatbots that can handle user free-text responses to open-ended questions and deliver engaging user experience. As the first step, we are investigating the feasibility and effectiveness of using publicly available, practical AI technologies to build effective interview chatbots. To demonstrate feasibility, we built a prototype scoped to enable interview chatbots with a subset of active listening skills-the abilities to comprehend a user's input and respond properly. To evaluate the effectiveness of our prototype, we compared the performance of interview chatbots with or without active listening skills on four common interview topics in a live evaluation with 206 users. Our work presents practical design implications for building effective interview chatbots, hybrid chatbot platforms, and empathetic chatbots beyond interview tasks. To investigate the feasibility of using publicly available technologies for building effective interview chatbots and the effect of such chatbots, we have presented a prototype that combines a rule-based chatbot builder with data-driven models to power interview chatbots with active listening skills. These skills enable a chatbot to better handle complex and diverse user responsesto open-ended interview questions. As a result, such a chatbot delivers more engaging user experience and elicit higher-quality user responses.

"
BlyncSync: Enabling Multimodal Smartwatch Gestures with Synchronous Touch and Blink,https://dl.acm.org/doi/10.1145/3313831.3376132,"
Input techniques have been drawing abiding attention along with the continual miniaturization of personal computers. In this paper, we present BlyncSync, a novel multi-modal gesture set that leverages the synchronicity of touch and blink events to augment the input vocabulary of smartwatches with a rapid gesture, while at the same time, offers a solution to the false activation problem of blink-based input. BlyncSync contributes the concept of a mutual delimiter, where two modalities are used to jointly delimit the intention of each other's input. A study shows that BlyncSync is 33% faster than using a baseline input delimiter (physical smartwatch button), with only 150ms in overhead cost compared to traditional touch events. Furthermore, our data indicates that the gesture can be tuned to elicit a true positive rate of 97% and a false positive rate of 1.68%. We have presented BlyncSync, a set of multi-modal smartwatch gestures that were designed as input delimiters for both touch and eye input. Our work introduces the concept of mutual delimiters and offers a design space of Touch & Blink gestures. Our experiments showed that the BlyncSync gestures are resistant to false positives, while still achieving high true positive rates. Since BlyncSync is easy to perform and unlikely to be accidentally invoked, it provides an always-active input method for smartwatch interaction. Based on the study results, we further provide insights to the trade-off of selecting activation thresholds, which could enable deployments of BlyncSync within commercial products. Furthermore, since the synchronous touch and eye events serve as mutual delimiters, BlyncSync spans a unique application space that covers both smartwatch interaction and gaze input, as demonstrated by our sample applications. We hope our technique will serve as important groundwork for future work on multimodal wearable input.

"
"Making Space for Social Sharing: Insights from a Community-Based Social Group for
                                 People with Dementia",https://dl.acm.org/doi/10.1145/3313831.3376133,"
People with dementia face major challenges in maintaining active social interaction. Designing digital tools for social sharing within families and care facilities has been well explored by HCI research, but comparatively less work has considered community settings. Situated in a community-based program for storytelling and socializing, our field observations and semi-structured interviews with people living with early-middle stage dementia, family caregivers, and program facilitators illustrate both positive and challenging aspects of social activities. We contribute a nuanced understanding of participants' social lives and identify four factors that aid in achieving positive outcomes: effective agencies for social interaction, normalized and friendly environments, collaboration and teamwork, and mediating social cues and communication. Finally, we examine our findings through the lens of past HCI work and offer insights for designing new social technologies to diversify the range of social spaces in community settings, through expanding peer collaboration, leveraging physical and virtual spaces, creating open-ended experiences, and developing flexible platforms. Our recent fieldwork in the Tales & Travels storytelling and social program, distinctive in its community setting, reveals the potential to diversify social sharing spaces for people with dementia, thus informing the design of new social technologies. On the basis of thematic analysis on interview transcripts and observation notes, we propose to further community-based peer collaboration and balance the tension between co-located and technology-mediated spaces. We suggest richer content, more open-ended structures, and synchronized creating and sharing processes, diversifying the roles of people with dementia in social interaction. We further discuss developing more flexible social platforms to offer person-centered yet inclusive activities.
"
Phasking on Paper: Accessing a Continuum of PHysically Assisted SKetchING,https://dl.acm.org/doi/10.1145/3313831.3376134,"
When sketching, we must choose between paper (expressive ease, ruler and eraser) and computational assistance (parametric support, a digital record). PHysically Assisted SKetching provides both, with a pen that displays force constraints with which the sketcher interacts as they draw on paper. Phasking provides passive, ""bound"" constraints (like a ruler); or actively ""brings"" the sketcher along a commanded path (e.g., a curve), which they can violate for creative variation. The sketcher modulates constraint strength (control sharing) by bearing down on the pen-tip. Phasking requires untethered, graded force-feedback, achieved by modifying a ballpoint drive that generates force through rolling surface contact. To understand phasking's viability, we implemented its interaction concepts, related them to sketching tasks and measured device performance. We assessed the experience of 10 sketchers, who could understand, use and delight in phasking, and who valued its control-sharing and digital twinning for productivity, creative control and learning to draw. Our evaluations indicate that this prototype was sufficient to assess phasking’s potential. The concept found an enthusiastic reception, and feedback points to key improvements. With a full interactive experience in place, we have proved possible many other interesting functions within this framework, including modifying elements (e.g., resize, rotate, amend) as well as copy, paste, undo; identifying free-drawn marks as parametric objects; combining objects into a virtual construct, and even simulating dynamic virtual systems. It is a small straightforward step to full digital twinning: modify it onscreen then bring it back to paper with guided tracing. Phasking is too different from other digital tools to know its full potential. Being untethered, portable and self-contained, Phasking Pen can, with attainable modifications, be used on arbitrary surfaces. This could lead to a new way of ‘drawing on a napkin’, support blind mobility by revealing maps on a corridor wall, and allow drawing and playing with simulations on a whiteboard – an ‘object to think with’ [28, 30].

"
"Peer-to-Peer Energy Markets: Understanding the Values of Collective and Community
                                 Trading",https://dl.acm.org/doi/10.1145/3313831.3376135,"
Peer-to-peer energy-trading platforms (P2P) have the potential to transform the current energy system. However, research is presently scarce on how people would like to participate in, and what would they expect to gain from, such platforms. We address this gap by exploring these questions in the context of the UK energy market. Using a qualitative interview study, we examine how 45 people with an interest in renewable energy understand P2P. We find that the prospective users value the collective benefits of P2P, and understand participation as a mechanism to support social, ecological and economic benefits for communities and larger groups. Drawing on the findings from the interview analysis, we explore broad design characteristics that a prospective P2P energy trading platform should provide to meet the expectations and concerns voiced by our study participants. We extend HCI research examining P2P energy markets by analyzing how prospective users understand, value and seek to engage in these platforms, with a focus on members of the public who have a pre-existing interest in renewable energy. Our participants valued experiences that enable communities to organize around shared values, build an understanding of P2P platforms and the ways that trading impacts the environment, and to configure their own selective engagement with business models and broader energy infrastructure. Our analysis emphasizes the importance of nurturing and supporting groups within P2P energy-trading platforms, particularly for populations who already have an interest and engagement with renewable energy. Likewise, our findings are consistent with existing research that highlights the need for autonomy, control and economic equality in these markets. More broadly, our research speaks to examinations of the sharing economy, we bring together research that emphasizes the social dimensions of sharing with calls to examine the social justice implications of sharing-economy applications. Specifically, we outline how users can harness groups to advance sustainability aims and how platforms can provide infrastructure and opportunities to support these efforts. Thus, our contributions can provide insights for the HCI community, private companies and policy makers in developing P2P energy markets.
"
AirTouch: 3D-printed Touch-Sensitive Objects Using Pneumatic Sensing,https://dl.acm.org/doi/10.1145/3313831.3376136,"
3D printing technology can be used to rapidly prototype the look and feel of 3D objects. However, the objects produced are passive. There has been increasing interest in making these objects interactive, yet they often require assembling components or complex calibration. In this paper, we contribute AirTouch, a technique that enables designers to fabricate touch-sensitive objects with minimal assembly and calibration using pneumatic sensing. AirTouch-enabled objects are 3D printed as a single structure using a consumer-level 3D printer. AirTouch uses pre-trained machine learning models to identify interactions with fabricated objects, meaning that there is no calibration required once the object has completed printing. We evaluate our technique using fabricated objects with various geometries and touch sensitive locations, obtaining accuracies of at least 90% with 12 interactive locations. In this paper we introduced AirTouch: a technique for fabricating touch-sensitive objects without the need of any postprint activities such as assembly or calibration. We presented the theory behind AirTouch, our explorations of parameters for both interaction and successful fabrication, and guidelines for designing AirTouch-enabled objects. We illustrated AirTouch’s flexibility with several applications, and showed that AirTouch is able to identify interactions with accuracies of at least 91% with 12 interactive locations.

"
Digital Liminalities: Understanding Isolated Communities on the Edge,https://dl.acm.org/doi/10.1145/3313831.3376137,"
This paper brings together three distinct case studies to explore how social isolation and notions of liminality shape ontological security within communities on ""the edge"" of society. Each case study exemplifies the differing nature of liminality in everyday contexts and the extent to which increased digitalisation perturbs it in multiple ways. Taking an ethnographic approach, the research engaged with seafarers onboard container ships in European waters, communities in Greenland and welfare claimants in the North East of England. It posits that technological innovation must attend to the routinisation of everyday life through which people establish ontological security if such innovation is to be supportive. The paper thus moves beyond existing HCI scholarship by foregrounding the contextual and relational aspects of social isolation rather than the technological. It does so by advocating a ground-up design process that considers ontological security in relation to notions of liminality among communities on the edge. Grounding our findings in three distinct communities on the edge of society, we have shown how social isolation and feelings of security are interwoven and shape digital interactions. The three case studies also highlight the differing nature of liminality in everyday contexts and how spaces “between” connected and disconnected – and transitions between the two – perturbs everyday routines needed for the individual to establish ontological security. We have suggested how the HCI community can support digital design that attends to people’s sense of security and experience of liminality. This can be done by designing interventions and community-led engagements that attend to wider social, political economic and geographical aspects shaping social isolation. We see this paper as a starting point for a wider programme of engagements with communities experiencing social isolation on the edge of society, focusing on their sense of collective and individual security. We posit that the HCI community is uniquely positioned to lead such a programme.
"
"Mouillé: Exploring Wetness Illusion on Fingertips to Enhance Immersive Experience
                                 in VR",https://dl.acm.org/doi/10.1145/3313831.3376138,"
Providing users with rich sensations is beneficial to enhance their immersion in Virtual Reality (VR) environments. Wetness is one such imperative sensation that affects users' sense of comfort and helps users adjust grip force when interacting with objects. Researchers have recently begun to explore ways to create wetness illusions, primarily on a user's face or body skin. In this work, we extended this line of research by creating wetness illusion on users' fingertips. We first conducted a user study to understand the effect of thermal and tactile feedback on users' perceived wetness sensation. Informed by the findings, we designed and evaluated a prototype---Mouillé---that provides various levels of wetness illusions on fingertips for both hard and soft items when users squeeze, lift, or scratch it. Study results indicated that users were able to feel wetness with different levels of temperature changes and they were able to distinguish three levels of wetness for simulated VR objects. We further presented applications that simulated an ice cube, an iced cola bottle, and a wet sponge, etc, to demonstrate its use in VR. In this work, we first conducted a study to understand how temperature, pressure, and friction affect people’s wetness perception on fingertips using simulated dry-stimuli. Informed by the findings, we designed and implemented a prototype— Mouillé—that allows VR users to experience wetness on their fingertips. We conducted a user study in which VR users interacted with four wet virtual objects that were of different stiffness by squeezing, lifting, or scratching Mouillé. The results showed that users were able to feel different types of wetness with different levels of temperature changes and ways of interaction. Moreover, they were also able to distinguish three levels of wetness for each each type of wetness on a VR object (i.e., ice cube, coke bottle, sponge, and glass table). In sum, we found that temperature change is key to generating wetness illusions; pressure and friction could further enhance such perception if only they are carefully designed to not override the wetness sensation. Mouillé took a step further to enhance VR users’ immersive experiences by providing them with simulated wetness sensation to their fingertips with dry stimuli. We have discussed the factors (e.g., weight and surface textual of the prototype, the duration of the wetness illusions, individual difference) that should be examined to enhance wetness experience in VR.
"
"Replicate and Reuse: Tangible Interaction Design for Digitally-Augmented Physical
                                 Media Objects",https://dl.acm.org/doi/10.1145/3313831.3376139,"
Technology has transformed our physical interactions into infinitely more scalable and flexible digital ones. We can peruse an infinite number of photos, news articles, and books. However, these digital experiences lack the physical experience of paging through an album, reading a newspaper, or meandering through a bookshelf. Overlaying physical objects with digital content using augmented reality is a promising avenue towards bridging this gap. In this paper, we investigate the interaction design for such digital-overlaid physical objects and their varying levels of tangibility. We first conduct a user evaluation of a physical photo album that uses tangible interactions to support physical and digital operations. We further prototype multiple objects including bookshelves and newspapers and probe users on their usage, capabilities, and interactions. We then conduct a qualitative investigation of three interaction designs with varying tangibility that use three different input modalities. Finally, we discuss the insights from our investigations and recommend design guidelines. We investigated the interaction design questions pertaining to using a single physical media object to provide the physical experience for all corresponding digital content. We define the design problem, and build a wholly-tangible physical album prototype, plus several other prototypes including a bookshelf, newspaper, research paper, card-deck, and jigsaw-puzzle. We conducted a study that informed us on their utility and on the use of the wholly-tangible physical album. We further conducted a second study that compared three modalities of input and analyzed the trade-offs between tangibility, usability, and enjoyment. Finally, we summarized the design insights and discussed future directions. The reinstrumentation of physical objects for digital purposes is emerging as a strong direction for augmented reality applications. We believe our work opens a dialogue in this space on how to bring back our physical experiences while retaining the digital scale and flexibility.

"
"FDHelper: Assist Unsupervised Fraud Detection Experts with Interactive Feature Selection
                                 and Evaluation",https://dl.acm.org/doi/10.1145/3313831.3376140,"
Online fraud is the well-known dark side of the modern Internet. Unsupervised fraud detection algorithms are widely used to address this problem. However, selecting features, adjusting hyperparameters, evaluating the algorithms, and eliminating false positives all require human expert involvement. In this work, we design and implement an end-to-end interactive visualization system, FDHelper, based on the deep understanding of the mechanism of the black market and fraud detection algorithms. We identify a workflow based on experience from both fraud detection algorithm experts and domain experts. Using a multi-granularity three-layer visualization map embedding an entropy-based distance metric ColDis, analysts can interactively select different feature sets, refine fraud detection algorithms, tune parameters and evaluate the detection result in near real-time. We demonstrate the effectiveness and significance of FDHelper through two case studies with state-of-the-art fraud detection algorithms, interviews with domain experts and algorithm experts, and a user study with eight first-time end users. In this work, we presented FDHelper, an interactive visualization tool that supports fraud detection algorithm experts to fine-tune the weights and features timely. The workflow of using FDHelper was proposed based on the deep understanding of the requirements of both algorithm experts and domain experts. The three key designs in the workflow - choosing the algorithm and dataset, refining the feature selection and algorithm setting, and evaluating the detection result - are identified to guide the implementation of FDHelper. It brings the controllability, readability, and dependability to visual fraud detection. We next propose a multi-granularity three-layer visualization map with in-situ configuration to enable users to refine and check a fraud detection progress in time from the algorithm level, feature level, and the hyperparameter level. FDHelper works for fine-tuning both supervised algorithms and unsupervised algorithms. We also prove the efficiency through two real-world datasets and two state-of-the-art algorithms respectively. To the best of our knowledge, our work is the first interactive visual fraud detection system based on the grouping behavior of online fraud users. We hope this work can inspire both algorithm experts and visualization researchers on the subject of interactive fraud detection.

"
Understanding Walking Meetings: Drivers and Barriers,https://dl.acm.org/doi/10.1145/3313831.3376141,"
There is increased interest in reducing sedentary behavior of office workers to combat the negative health effects of prolonged sitting. Walking meetings offer a promising solution to this problem as they facilitate a physically active way of working. To inform future development of technologies supporting these type of meetings, in-depth qualitative insights into people's experiences of walking meetings are needed. We conducted semi-structured walking interviews (N=16) to identify key drivers and barriers for walking meetings in a living lab setting by using the 'WorkWalk'. The 'WorkWalk' is a 1.8 km walking route indicated by a dotted blue line with outdoor meeting points, integrated into the room booking system. Our findings provide insights into how walking meetings are experienced and affect the set-up and social dynamics of meetings. We offer design recommendations for the development of future technologies and service design elements to support walking meetings and active ways of working. Walking meetings are an adequate means to integrate physical activity within office work. Our research shows how design can facilitate the uptake and adoption of walking meetings. We offer an in-depth qualitative understanding of the drivers and barriers associated with walking meetings, revealing the social implications and variance of this practice. The deployment of the WorkWalk allowed us to find different scenarios and recommendations for walking meetings that could be used as a basis to redesign the workplace. This study sets the stage for future HCI research explorations and the development of supporting technologies for walking meetings and other active ways of working. Challenging current work paradigms allows us to rethink the office environment, the relations within that space, and improve these environments to increase efficiency, effectiveness and overall quality of work life. Let us take inspiration from great philosophers such as Nietzsche who said, “all truly great thoughts are conceived while walking” and follow their thread.
"
"Listen to Developers! A Participatory Design Study on Security Warnings for Cryptographic
                                 APIs",https://dl.acm.org/doi/10.1145/3313831.3376142,"
The positive effect of security information communicated to developers through API warnings has been established. However, current prototypical designs are based on security warnings for end-users. To improve security feedback for developers, we conducted a participatory design study with 25 professional software developers in focus groups. We identify which security information is considered helpful in avoiding insecure cryptographic API use during development. Concerning console messages, participants suggested five core elements, namely message classification, title message, code location, link to detailed external resources, and color. Design guidelines for end-user warnings are only partially suitable in this context. Participants emphasized the importance of tailoring the detail and content of security information to the context. Console warnings call for concise communication; further information needs to be linked externally. Therefore, security feedback should transcend tools and should be adjustable by software developers across development tools, considering the work context and developer needs. Insecure CAPI use is a critical issue for software security with far-reaching consequences for users [31, 1]. Our work contributes to a potential mitigation of the problem. While previous work showed that API redesign [1], improved documentation [2] and better tool support [33] are promising directions, we follow another line of research and improve a proposal for CAPI based console security feedback [17]. Our participatory design approach helped to identify areas of improvement for existing approaches. The FG sessions uncovered specific design aspects for CAPI warnings compared to other warnings in the developer console. Most of our participants would implement such a security warning for CAPIs. They designed these in the FGs, but went one step further: They discussed how much information they need and prefer in which phase of their development process. Our results can support API developers and researchers in further developing usable Cws.
"
ReCog: Supporting Blind People in Recognizing Personal Objects,https://dl.acm.org/doi/10.1145/3313831.3376143,"
We present ReCog, a mobile app that enables blind users to recognize objects by training a deep network with their own photos of such objects. This functionality is useful to differentiate personal objects, which cannot be recognized with pre-trained recognizers and may lack distinguishing tactile features. To ensure that the objects are well-framed in the captured photos, ReCog integrates a camera-aiming guidance that tracks target objects and instructs the user through verbal and sonification feedback to appropriately frame them. We report a two-session study with 10 blind participants using ReCog for object training and recognition, with and without guidance. We show that ReCog enables blind users to train and recognize their personal objects, and that camera-aiming guidance helps novice users to increase their confidence, achieve better accuracy, and learn strategies to capture better photos. We designed and developed ReCog, an interactive smartphone application that enables blind people to recognize their personal objects. This is achieved by capturing photos of such objects and training a recognition model with them. This approach complements general object recognizers, which can recognize common objects only, and crowdsourcing approaches, which rely on human intervention for detailed object recognition. Since capturing well-framed photos is a known diffculty for blind people, we augmented our system with a camera-aiming guidance module that supports the users while capturing photos. We evaluated the system with 10 blind participants who found it to be usable and accurate. During Session 1, we uncovered a subjective preference for camera-aiming guidance. The analysis of the captured photos confrmed that the use of the guidance modality results in more consistent photo capturing. In particular, the captured objects are better centered and scaled with respect to the photo frame. During Session 2, the participants gradually started to prefer to use the system without camera-aiming guidance as they improved and acquired confdence in their photo taking skills through prolonged usage of the system. However they still felt more confdent using the system with camera-aiming guidance for the training of the object recognizer to ensure a higher recognition accuracy. We also discovered specifc limitations due to the nature of the object recognition technology. While single photos are suffcient at testing time, multiple photos of an object need to be captured during the training, which users may fnd cumbersome. The system relies on the labeling of the trained objects, which may require sighted assistance or the using an external system. As a future work, we will integrate ReCog with general object recognizers and crowdsourcing approaches in order to minimize the user’s need for intervention.
"
Breaking The Experience: Effects of Questionnaires in VR User Studies,https://dl.acm.org/doi/10.1145/3313831.3376144,"
Questionnaires are among the most common research tools in virtual reality (VR) evaluations and user studies. However, transitioning from virtual worlds to the physical world to respond to VR experience questionnaires can potentially lead to systematic biases. Administering questionnaires in VR (inVRQs) is becoming more common in contemporary research. This is based on the intuitive notion that inVRQs may ease participation, reduce the Break in Presence (BIP) and avoid biases. In this paper, we perform a systematic investigation into the effects of interrupting the VR experience through questionnaires using physiological data as a continuous and objective measure of presence. In a user study (n=50), we evaluated question-asking procedures using a VR shooter with two different levels of immersion. The users rated their player experience with a questionnaire either inside or outside of VR. Our results indicate a reduced BIP for the employed inVRQ without affecting the self-reported player experience. Questionnaires are widespread measurement instruments to assess subjective responses on a particular experience in VR user studies. However, research on presence shows evidence that switching between VR and physical reality leads to a break in presence [48, 89] that might alter the outcomes of the self-reports [74], especially when assessing constructs that are sensitive to disturbance and should be assessed with the least possible invasion. Researchers started to administer questionnaires in VR, which most likely reduce the BIP [29]. Yet, related work offered no clear evidence whether INVRQS diminish the BIP and to what extent filling out questionnaires contributes to a BIP. In this paper, we investigated how question-asking itself breaks the VR experience (H1) and if INVRQS can minimize the break in presence (H2) and therefore, reduce uncontrolled biases in performance (H3) and self-reports (H4). To investigate our hypotheses, we conducted a user study (n=50) where we recorded biosignals of subjects while they played a simple VR shooter either with low or high visual fidelity and filled out questionnaires regarding their PX both in VR and on PC in physical reality. Our results clearly show that both questionnaire modalities produce BIPs. Moreover, the physiological responses in the EDA for INVRQS are significantly lower and shorter than to OUTVRQS. These results show evidence that INVRQS are less invasive than OUTVRQS and provide more reliable self-reports. Our findings suggest an influence of BIPs on performance of subsequent tasks. Moreover, these effects might become even more prominent in VEs high-quality VR experiences, such as AAA games as there is “more immersion to break”. Our findings can help researchers and designers to apply the appropriate instruments for their study design and lay groundwork for the design of INVRQS to provide validated and standardized methods of question-asking in VR.

"
"""Hey Model!"" – Natural User Interactions and Agency in Accessible Interactive 3D Models",https://dl.acm.org/doi/10.1145/3313831.3376145,"
While developments in 3D printing have opened up opportunities for improved access to graphical information for people who are blind or have low vision (BLV), they can provide only limited detailed and contextual information. Interactive 3D printed models (I3Ms) that provide audio labels and/or a conversational agent interface potentially overcome this limitation. We conducted a Wizard-of-Oz exploratory study to uncover the multi-modal interaction techniques that BLV people would like to use when exploring I3Ms, and investigated their attitudes towards different levels of model agency. These findings informed the creation of an I3M prototype of the solar system. A second user study with this model revealed a hierarchy of interaction, with BLV users preferring tactile exploration, followed by touch gestures to trigger audio labels, and then natural language to fill in knowledge gaps and confirm understanding. In this paper we have presented two user studies investigating blind and low vision (BLV) peoples’ preferred interaction techniques and modalities for interactive 3D printed models (I3Ms). Study 1 utilised a Wizard-of-Oz methodology, and Study 2 confirmed the results by evaluating the use of a prototype I3M of the solar system the design of which was informed by the findings of Study 1. We found that participants wished to use a mix of tactile exploration, touch triggered passive audio labels, and natural language questioning to obtain information from the model with a mix of audio and haptic output. They enjoyed engaging with models that had multiple parts, and would remove parts to further explore and compare them. When talking to the model, participants treated it as a conversational agent and indicated that they preferred more intelligent models that support natural language and which, when appropriate, could provide guidance to the user. Participants wished to be as independent as possible and establish their own interpretations. They wanted to initiate interactions with the model and generally preferred lower model agency. However, they did want the model to intervene if they did something wrong such as placing a component in the wrong place. The desire for independent exploration led to a hierarchy of interaction modalities: most participants preferred to glean information and answer questions using tactile exploration, then to use touch triggered audio labels for specific details, finally using natural language questions to obtain information not in the label or to confirm their understanding. However, interaction choices were driven by participants’ prior tactile and technological experiences. Not only are these findings of significance to the assistive technology community, they also have wider implications to HCI. In particular the combination of I3Ms with conversational agents suggests a radically new kind of embodied conversational agent, one that is physically embodied and that can be perceived tactually by a BLV person, rather than the traditional embodied conversational agent that is perceived visually and has a human-like experience [14]. Such physically embodied conversational agents raise many interesting research questions, including their perceived agency, autonomy and acceptance by the end user. There are also many questions to be answered on how such agents can be implemented. A major focus of our future research will be to design and construct a fully functional prototype, conduct more extensive user evaluations with a variety of models, including maps, and to explore whether model agency preferences differ with age and environment.

"
Meta-AR-App: An Authoring Platform for Collaborative Augmented Reality in STEM Classrooms,https://dl.acm.org/doi/10.1145/3313831.3376146,"
Augmented Reality (AR) has become a valuable tool for education and training processes. Meanwhile, cloud-based technologies can foster collaboration and other interaction modalities to enhance learning. We combine the cloud capabilities with AR technologies to present Meta-AR-App, an authoring platform for collaborative AR, which enables authoring between instructors and students. Additionally, we introduce a new application of an established collaboration process, the pull-based development model, to enable sharing and retrieving of AR learning content. We customize this model and create two modalities of interaction for the classroom: local (student to student) and global (instructor to class) pull. Based on observations from our user studies, we organize a four-category classroom model which implements our system: Work, Design, Collaboration, and Technology. Further, our system enables an iterative improvement workflow of the class content and enables synergistic collaboration that empowers students to be active agents in the learning process. We presented Meta-AR-App, an authoring platform for collaborative AR. We demonstrated how we can leverage the medium of AR combined with cloud technologies to support selective (i.e., high quality) and timely collaboration, which enables a decrease in error during problem-solving. Apart from these novel interaction modalities, we observed how iterative improvement of the AR learning content (global pull) based on previous contributions made by students (local pull) can improve the original AR project and spark curiosity and creativity among students’ learning process. The next step will be to explore scaling the system to support a community of contributors with reusable templates of project-based AR learning content. The unique aspect of our technology for STEM learning is that it encourages discoveries of complex concepts through a trial-and-error exploration and facilitates effective debugging individually and collectively.

"
PenSight: Enhanced Interaction with a Pen-Top Camera,https://dl.acm.org/doi/10.1145/3313831.3376147,"
We propose mounting a downward-facing camera above the top end of a digital tablet pen. This creates a unique and practical viewing angle for capturing the pen-holding hand and the immediate surroundings which can include the other hand. The fabrication of a prototype device is described and the enabled interaction design space is explored, including dominant and non-dominant hand pose recognition, tablet grip detection, hand gestures, capturing physical content in the environment, and detecting users and pens. A deep learning computer vision pipeline is developed for classification, regression, and keypoint detection to enable these interactions. Example applications demonstrate usage scenarios and a qualitative user evaluation confirms the potential of the approach. We presented PenSight, a concept to enhance pen interaction for tablets by attaching a camera to the top of the pen. We built prototypes using a fisheye camera and 3D-printed mounts to explore several examples of techniques enabled by this paradigm. These include posture-based interaction using both hands, individually or in tandem, interacting with physical documents in the surrounding environment and identifying users and the attached pen. We examined postures and off-tablet interaction in more depth with two demonstration applications. The results of our qualitative evaluation demonstrate potential for postures formed by the other hand when not holding the tablet and for some poses of the pen-holding hand. There are doubtless many other possible techniques that can be realised. Overall, we believe PenSight provides a simple holistic mobile sensing solution for capturing and interpreting interactions of the two hands as well as the surrounding environment.

"
From Data to Insights: A Layered Storytelling Approach for Multimodal Learning Analytics,https://dl.acm.org/doi/10.1145/3313831.3376148,"
Significant progress to integrate and analyse multimodal data has been carried out in the last years. Yet, little research has tackled the challenge of visualising and supporting the sensemaking of multimodal data to inform teaching and learning. It is naïve to expect that simply by rendering multiple data streams visually, a teacher or learner will be able to make sense of them. This paper introduces an approach to unravel the complexity of multimodal data by organising it into meaningful layers that explain critical insights to teachers and students. The approach is illustrated through the design of two data storytelling prototypes in the context of nursing simulation. Two authentic studies with educators and students identified the potential of the approach to create learning analytics interfaces that communicate insights on team performance, as well as concerns in terms of accountability and automated insights discovery. As humans struggle with the data tsunami, we are now awash with dashboard prototypes and products. Yet, there is growing evidence that these are far from intuitive. This paper documents how we have wrestled with the challenge of designing activity-based feedback visualisations which draw the attention of non-technical users to key insights in the data. We argue, supported by user studies, that this work advances the state of the art in making multimodal data streams intelligible to non-data experts. The approach should enable similar collocated activities to benefit from these novel collaboration analytics.
"
Computing Students' Learning Difficulties in HCI Education,https://dl.acm.org/doi/10.1145/3313831.3376149,"
Software developers often make interface design decisions and work with designers. Therefore, computing students who seek to become developers need some education about interface design. While prior work has studied difficulties that educators face when teaching design to computing students, there is comparatively little work on the difficulties computing students face when learning HCI design skills. To uncover these difficulties, we conducted two qualitative studies consisting of surveys and interviews with (1) computing students and (2) educators who teach interface design to computing students. Qualitative analysis of their responses revealed 18 types of learning difficulties students might experience in HCI design education, including difficulties around the mechanics of design work, project management skills, the wicked nature of design problems, and distorted perspectives on design. Nonetheless, our findings reveal a number of interesting implications for research. For instance, how prevalent are these difficulties in broader contexts? Under what conditions (e.g., studio-based vs. traditional lecture-based classes) might computing students experience these kinds of difficulties more or less often? As HCI expands beyond higher education into primary and secondary curricula (like Exploring Computer Science [24] or Code.org [1]), will these learning difficulties still hold? And what are effective strategies to mitigate students’ learning difficulties that fit these categories? The RUSH difficulty revealed by educators in Study 2 also suggests an interesting hypothesis: the way we teach computing students to create software and write code may make them less likely to succeed at interface design work. Future work in this area should explore the extent to which prior computing knowledge influences students’ experiences with these difficulties. Our results also contribute to the discourse around pedagogical content knowledge (PCK) [63] development for HCI design education. PCK is domain-specific [29, 35, 37] and consists of knowledge of pedagogical strategies to teach a particular topic, in a particular context, to a particular audience. Exact definitions of the components of PCK vary (c.f. [8, 19, 50]), but knowledge of student learning difficulties is generally considered a core aspect. Our field has only begun to investigate the nature of computing PCK within the past decade, from primary and secondary learning environments [6, 21, 49, 59, 67], to both general [34, 35] and specific [39, 40, 44, 47, 52, 53, 69] aspects of post-secondary CS education. A prior study of ours did explore PCK for teaching software interface design skills [53], but it was scoped specifically to teaching a particular gender-inclusive interface design method and focused on educators’ pedagogical strategies rather than students’ perspectives. Therefore, the set of student learning difficulties described in this paper provides some of the first foundations for future research on PCK for general HCI design education. Further exploring this space might enable more effective use of instruction time in HCI classes (which are known to suffer from time constraints already [15]) through the development of more effective learning materials, or even help shorten the onboarding time for new HCI design educators—an important pursuit to ensure we have enough teachers to keep pace with the rapid growth of computing education. Equipped with this better understanding of student learning difficulties, we can begin to deepen our understanding of how to provide computing students with effective design educations. Implementing this newly gained knowledge in curricula and pedagogy will lead to better teaching and learning around HCI design concepts. Through this effort, the software industry as a whole will benefit from a pool of design-literate computing graduates who enter the workforce ready to understand and contribute to many aspects of large projects, aware of the impacts of their design choices. Developers will be empowered to design usable, accessible, ethical, and inclusive software interfaces, allowing more diverse populations to engage with various technologies and participate in today’s computing-infused world.
"
Evaluating 'Prefer not to say' Around Sensitive Disclosures,https://dl.acm.org/doi/10.1145/3313831.3376150,"
As people's offline and online lives become increasingly entwined, the sensitivity of personal information disclosed online is increasing. Disclosures often occur through structured disclosure fields (e.g., drop-down lists). Prior research suggests these fields may limit privacy, with non-disclosing users being presumed to be hiding undesirable information. We investigated this around HIV status disclosure in online dating apps used by men who have sex with men. Our online study asked participants (N=183) to rate profiles where HIV status was either disclosed or undisclosed. We tested three designs for displaying undisclosed fields. Visibility of undisclosed fields had a significant effect on the way profiles were rated, and other profile information (e.g., ethnicity) could affect inferences that develop around undisclosed information. Our research highlights complexities around designing for non-disclosure and questions the voluntary nature of these fields. Further work is outlined to ensure disclosure control is appropriately implemented around online sensitive information disclosures. Whilst prior research found structured disclosure fields restricting forms of individual expression for marginalised groups [31], our findings suggest that these same disclosure fields can limit disclosure choice, and similarly disadvantage marginalised users. Whilst this work shows how design can be used to reduce the effect of privacy unraveling leading to an increase in disclosure control, this may not be effective for marginalised groups. This study shines a spotlight on a simple, yet commonly used form field, and raises further questions that need to be explored within this area of social research. This is needed to ensure disclosure control is appropriately implemented into these fields and to better understand how indirect disclosure may occur through their use.
"
Proximate Social Factors in First-Time Contribution to Online Communities,https://dl.acm.org/doi/10.1145/3313831.3376151,"
In the course of every member's integration into an online community, a decision must be made to participate for the first time. The challenges of effective recruitment, management, and retention of new users have been extensively explored in social computing research. However, little work has looked at in-the-moment factors that lead users to decide to participate instead of ""lurk"", conditions which can be shaped to draw new users in at crucial moments. In this work we analyze 183 million messages scraped from chatrooms on the livestreaming platform Twitch in order to understand differences between first-time participants' and regulars' behaviors and to identify conditions that encourage first-time participation. We find that presence of diverse types of users increases likelihood of new participation, with effects depending on the size of the community. We also find that information-seeking behaviors in first-time participation are negatively associated with retention in the short and medium term.
"
Data-driven Multi-level Segmentation of Image Editing Logs,https://dl.acm.org/doi/10.1145/3313831.3376152,"
Automatic segmentation of logs for creativity tools such as image editing systems could improve their usability and learnability by supporting such interaction use cases as smart history navigation or recommending alternative design choices. We propose a multi-level segmentation model that works for many image editing tasks including poster creation, portrait retouching, and special effect creation. The lowest-level chunks of logged events are computed using a support vector machine model and higher-level chunks are built on top of these, at a level of granularity that can be customized for specific use cases. Our model takes into account features derived from four event attributes collected in realistically complex Photoshop sessions with expert users: command, timestamp, image content, and artwork layer. We present a detailed analysis of the relevance of each feature and evaluate the model using both quantitative performance metrics and qualitative analysis of sample sessions. We developed a multi-level segmentation model for real-world image editing logs that works for three image editing tasks. We present evidence for what features are relevant and irrelevant for the segmentation. Results show that command and layer similarity are highly relevant, image-related features are not useful despite claims in previous work, and duration is debatable due to the limitation in data collection. We also present quantitative and qualitative evaluation of our segmentation model, and show that it performs reasonably well for the challenging problem of segmenting realistic logs that capture mistakes, experiments, and subtask switching.

"
Data Everyday: Data Literacy Practices in a Division I College Sports Context,https://dl.acm.org/doi/10.1145/3313831.3376153,"
Data analysis is central to sports training. Today, cutting-edge digital technologies are deployed to measure and improve athletes' performance. But too often researchers focus on the technology collecting performance data at the expense of understanding athletes' experiences with data. This is particularly the case in the understudied context of collegiate athletics, where competition is fierce, tools for data analysis abound, and the institution actively manages athletes' lives. By investigating how student-athletes analyze their performance data and are analyzed in turn, we can better understand the individual and institutional factors that make data literacy practices in athletics meaningful and productive-or not. Our pilot interview study of student-athletes at one Division I university reveals a set of opportunities for student-athletes to engage with and learn from data analytics practices. These opportunities come with a set of contextual tensions that should inform the design of new technologies for collegiate sports settings. Our findings have three major implications for research on HCI and Sports. First, personal informatics practices in sports settings could have an impact beyond the sport itself to include data literacy practices more broadly. Frameworks for data literacy can help us identify these practices and push them forward. Second, our findings suggest that the level of competition in Division I sports creates social and emotional dynamics that differentiate athletes’ experiences with data even from elite athletes in other contexts. Finally, our findings indicate that HCI and sports researchers need more study and consideration of the influence of organizational contexts on data practices. Further work is needed to more deeply explore the impacts of organizational infrastructure within specific sports, across multiple institutions, and beyond collegiate contexts. Additionally, more ethnographic approaches are needed to further explain how organizational infrastructures impact data literacy practices on a moment-to-moment basis. This pilot work guides our next steps geared toward understanding such nuances to develop learning tools and experiences for data literacy in sports play. Beyond HCI and sports, student-athletes’ experiences of data monitoring, particularly of health data (or even their academic data [63]), are similar to other workers’ experiences of, e.g., biometrics. However, Division 1 athletics’ high investment in athletes means they are likely the leading edge of trends that will filter out to the broader population as technologies cheapen and such managerial practices become more socially acceptable.
"
"TalkingBoogie: Collaborative Mobile AAC System for Non-verbal Children with Developmental
                                 Disabilities and Their Caregivers",https://dl.acm.org/doi/10.1145/3313831.3376154,"
Augmentative and alternative communication (AAC) technologies are widely used to help non-verbal children enable communication. For AAC-aided communication to be successful, caregivers should support children with consistent intervention strategies in various settings. As such, caregivers need to continuously observe and discuss children's AAC usage to create a shared understanding of these strategies. However, caregivers often find it challenging to effectively collaborate with one another due to a lack of family involvement and the unstructured process of collaboration. To address these issues, we present TalkingBoogie, which consists of two mobile apps: TalkingBoogie-AAC for caregiver-child communication, and TalkingBoogie-coach supporting caregiver collaboration. Working together, these applications provide contextualized layouts for symbol arrangement, scaffold the process of sharing and discussing observations, and induce caregivers' balanced participation. A two-week deployment study with four groups (N=11) found that TalkingBoogie helped increase mutual understanding of strategies and encourage balanced participation between caregivers with reduced cognitive loads. In this paper, we designed and evaluated TalkingBoogie, a collaborative AAC system that supports multiple caregivers to actively participate in the AAC-aided communication of a child. With two mobile applications, TalkingBoogie balances the participation of caregivers in collaboration and scaffolds the overall process of sharing and discussing observations on children. Through a two-week field evaluation, we could identify the feasibility of a collaborative AAC system.
"
texSketch: Active Diagramming through Pen-and-Ink Annotations,https://dl.acm.org/doi/10.1145/3313831.3376155,"
Learning from text is a constructive activity in which sentence-level information is combined by the reader to build coherent mental models. With increasingly complex texts, forming a mental model becomes challenging due to a lack of background knowledge, and limits in working memory and attention. To address this, we are taught knowledge externalization strategies such as active reading and diagramming. Unfortunately, paper-and-pencil approaches may not always be appropriate, and software solutions create friction through difficult input modalities, limited workflow support, and barriers between reading and diagramming. For all but the simplest text, building coherent diagrams can be tedious and difficult. We propose Active Diagramming, an approach extending familiar active reading strategies to the task of diagram construction. Our prototype, texSketch, combines pen-and-ink interactions with natural language processing to reduce the cost of producing diagrams while maintaining the cognitive effort necessary for comprehension. Our user study finds that readers can effectively create diagrams without disrupting reading. Based on models for science text comprehension, we present an end-to-end workflow for knowledge externalization called Active Diagramming. Through a probe study, we identified key features needed to support active diagramming. The result is texSketch, a pen-and-ink system for building diagrams during reading. With texSketch, we focus on helping the reader convert annotations they make in text into integrated mental models. The iterative process of select-organize-integrate lets readers take text-level annotations into connected propositions and then combine them. NLP-based features on key terms help focus the reader’s attention. Our interactions implement a consistent gesture language and allow readers flexibility in switching between text and diagram representations as they read. Our approach demonstrates a balance between providing readers with opportunities to learn through active diagramming while reducing non-desirable and distracting difficulties.

"
"""Out of Luck"": Socio-Economic Differences in Student Coping Responses to Technology
                                 Problems",https://dl.acm.org/doi/10.1145/3313831.3376156,"
Despite high levels of digital technology access among college students, technology disruption remains an issue. This study was conducted to understand how technology disruption might contribute to socio-economic disparities in academic performance. Data were analyzed from a non-representative sample of 748 undergraduate students. We examined socio-economic differences in types of technology problems students experience; the consequences of those problems; and beliefs about how to handle future problems. Socio-economic status was not associated with types of technology problems, but it was associated with greater negative consequences and less-efficacious beliefs about handling future situations. These findings are consistent with sociological work on socio-economic differences in student help-seeking. They also elaborate mechanistic understanding of the technology maintenance construct. Finally, for those interested in designing to reduce socio-economic inequalities, they suggest the need for interfaces that go beyond information accessibility to facilitate student empowerment and student-teacher communication. Technology has radically transformed how we learn and communicate in educational settings. The HCI community has invested a great time and resources trying to exploit these new tools to improve the learning experience, including tools for those from disadvantaged backgrounds. We hope these findings elaborate on the complexity of these issues, and offer additional nuance for understanding why design, and technology in general, is limited in what it is able to do to reduce educational inequalities [47]. One way to do this is to broaden awareness of the scope of factors that limit success for low-income students beyond a difference in skills and access to material resources. As our findings illustrate, it is the socio-emotional resources that may often be most consequential in shaping low-SES students’ successes. Appreciating these factors, and designing to support these differences, may be one way to help optimize the success of new digital tools in educational contexts.
"
Exploring Auditory Information to Change Users' Perception of Time Passing as Shorter,https://dl.acm.org/doi/10.1145/3313831.3376157,"
Although the processing speed of computers has been drastically increasing year by year, users still have to wait for computers to complete tasks or to respond. To cope with this, several studies have proposed presenting certain visual information to users to change their perception of time passing as shorter, e.g., progress bars with animated ribbing or faster/slower virtual clocks. As speech interfaces such as smart speakers are becoming popular, a novel method is required to make users perceive the passing of time as shorter by presenting auditory stimuli. We thus prepared 20 pieces of auditory information as experimental stimuli; that is, 11 auditory stimuli that have the same 10.1-second duration but different numbers of 0.1-second sine-wave sounds and 9 other auditory stimuli that have the same 10.1-second duration and numbers of sounds but different interval patterns between the sounds. We conducted three experiments to figure out which kinds of auditory stimuli can change users' perception of time passing as shorter. We found that a 10.1-second auditory stimulus that has 0.1-second sine-wave sounds appearing 11 times with intervals between the sounds that narrow rapidly in a linear fashion was perceived as shortest at about 9.3 seconds, which was 7.6% shorter than the actual duration of the stimulus. We also found that different interval patterns of sounds in auditory information significantly affected users' perception of time passing as shorter, while different numbers of sounds did not. In this paper, we explored which kinds of auditory stimuli can change how users perceive the passing of time on the basis of knowledge on filled-duration illusions, especially which auditory stimuli were perceived by the users as “I feel this sound is shorter.” Specifically, we conducted three experiments. In experiment 1, auditory stimuli that have the same duration but different numbers of elements were presented to the participants in a paired comparison manner. As a result, the participants felt that the stimuli with more elements had a shorter duration, while those with fewer elements had a longer one. In experiment 2, stimuli that had the same duration and numbers of stimuli but had different interval patterns between elements were also presented in a paired comparison manner. As a result, the participants felt that stimuli that got narrower had a shorter duration and those that got wider had a longer one. In experiment 3, we selected two stimuli from both experiments (one was perceived as having the shortest duration and the other as having the longest duration in each experiment), and these stimuli were presented independently. As a result, stimulus NLR, which was perceived as being the shortest in experiment 2, was perceived as being about 9.3 seconds, which was 7.6% shorter than the actual duration of the stimulus, and this estimated duration was significantly shorter than those of the other stimuli. We thus succeeded in finding an auditory stimulus that makes users feel that a duration of time is shorter than it actually is and in figuring out that the interval patterns of elements significantly affected the users’ perception of time passing as shorter, while the numbers of sounds did not. We are sure that this auditory stimulus can thus improve the user experience, especially when users have to wait for computers to complete tasks or to respond. Before implementing the results of this study in actual applications, we have to immediately conduct several subsequent experiments to clarify which kinds of parameters should be prepared for the auditory stimuli that get narrower, e.g., the numbers of elements, the durations of the stimuli, and transition patterns of intervals. Exploring such possible patterns of auditory stimuli will clarify the significant factors that effectively change how users perceive the passing of time.
"
Place-Based Policymaking and HCI: Opportunities and Challenges for Technology Design,https://dl.acm.org/doi/10.1145/3313831.3376158,"
There has been a growing interest in HCI in designing and developing technology to support democratic participation, particularly in the domain of urban planning or place-based research. In addition, the HCI field has increasingly considered the intersection of HCI and policymaking to understand how our research can have a broader impact. In this paper, we report on a series of workshops with citizens and city planners to explore place-based policymaking through the case study of neighbourhood planning in the UK. Our analysis highlights the tensions, opportunities and challenges faced by citizens in creating policy. Drawing from our findings, we stress the need for HCI to be actively involved in supporting, innovating and (re)designing civic policymaking processes while emphasising design considerations for the development of technological tools. We have shown how place-based policymaking processes are complex and difficult to access for citizens, with a myriad of problems communicating with experts, engaging citizens and writing policy. We have made a number of recommendations for HCI researchers to become actively involved in supporting, innovating and (re)designing policy processes, and to design tools embedded within policy enabling citizen voices to carry through to decision-making in a real way. Ultimately, we encourage the field of HCI to consider policy within their research so that rather than designing digital tools in isolation, we can begin to make a stronger impact in public policy. Place-based policy is only one context within which HCI researchers work, and we believe our findings could have broader implications for other policy domains, although we recognise further research is needed to validate this.
"
"Designing Clinical AAC Tablet Applications with Adults who have Mild Intellectual
                     Disabilities",https://dl.acm.org/doi/10.1145/3313831.3376159,"
Patients with mild intellectual disabilities (ID) face significant communication barriers within primary care services. This has a detrimental effect on the quality of treatment being provided, meaning the consultation process could benefit from augmentative and alternative communication (AAC) technologies. However, little research has been conducted in this area beyond that of paper-based aids. We address this by extracting design requirements for a clinical AAC tablet application from n=10 adults with mild ID. Our results show that such technologies can promote communication between general practitioners (GPs) and patients with mild ID by extracting symptoms in advance of the consultation via an accessible questionnaire. These symptoms act as a referent and assist in raising the awareness of conditions commonly overlooked by GPs. Furthermore, the application can support people with ID in identifying and accessing healthcare services. Finally, the participants identified 6 key factors that affect the clarity of medical images. AAC technologies have the potential to assist people with mild ID throughout all aspects of life, yet our findings show their use remains limited within the clinical context. Just one of the ten participants regularly utilized an aid (patient passport) during consultations, despite the call for the embedment of high-tech AAC devices being made as far back as 1997 [43]. One reason for this may be the lack of guidelines to assist developers in creating such technologies. The authors could only identify those disseminated by Gibson et al. [14–16] yet their studies suffered from a lack of end-user involvement. Consequently, we extracted design requirements for a clinical AAC application from ten people with mild ID. The participants believe that the aid can assist in mitigating barriers across the entire consultation process, beginning with reserving and accessing appointments. The primary method of promoting communication aligned with the views of the experts in [14–16], by supplying GPs with symptoms selected from an accessible questionnaire. This questionnaire should adapt to both the user’s accessibility and medical needs and utilize evidence on the health trends experienced by people with ID. As such, commonly overlooked conditions may also be brought to the attention of the GP and potential time constraints may be alleviated.
"
Pronto: Rapid Augmented Reality Video Prototyping Using Sketches and Enaction,https://dl.acm.org/doi/10.1145/3313831.3376160,"
Designers have limited tools to prototype AR experiences rapidly. Can lightweight, immediate tools let designers prototype dynamic AR interactions while capturing the nuances of a 3D experience? We interviewed three AR experts and identified several recurring issues in AR design: creating and positioning 3D assets, handling the changing user position, and orchestrating multiple animations. We introduce PROJECT PRONTO, a tablet-based video prototyping system that combines 2D video with 3D manipulation. PRONTO supports four intertwined activities: capturing 3D spatial information alongside a video scenario, positioning and sketching 2D drawings in a 3D world, and enacting animations with physical interactions. An observational study with professional designers shows that participants can use PRONTO to prototype diverse AR experiences. All participants performed two tasks: replicating a sample non-trivial AR experience and prototyping their open-ended designs. All participants completed the replication task and found PRONTO easy to use. Most participants found that PRONTO encourages more exploration of designs than their current practices. We presented PRONTO, a rapid prototyping tool for AR experiences that uses augmented video, sketching, and enaction using a tablet. We interviewed three AR expert designers and formulated a set of design goals to address the current limitations of AR prototyping tools. Based on these goals, we have demonstrated an end-to-end workflow and interaction technique to create and modify AR objects on an augmented recorded video. Our work expands the body of HCI research in prototyping tools for AR by combining sketching, enaction, and augmented video. Finally, we evaluated the system with expert AR designers, showing the potential of the workflow for rapid prototyping in contrast to current practices. Our work suggests several interesting directions for future research. We would like to explore enhanced capturing capabilities to facilitate the creation of interaction during playback. To this end, we would like to employ state-of-the-art computer vision and sensing capabilities to capture user actions—hand gestures, gaze, and skeleton tracking—and environment information, such as a 3D depth map. This would significantly enhance the drawing and animation workflow for better spatiotemporal anchoring. For instance, the designer can sketch an object and attach it to the user’s hand in the recorded video. We would also like to enhance the capture with audio to prototype voice interaction. Timing animations and coordinating them with the changing user viewpoint is a weakness of our current system. We would like to investigate enhancing this while still maintaining the simplicity of a single timeline. We would also like to explore incorporating multiple video captures to accommodate changing environments or multiple viewpoints. Although our current workflow requires the designer to be in the same space for capturing and prototyping, in the future, we would like to explore remote capturing, working with scales spanning from the miniature to the massive, e.g., underwater or a drone-captured urban space. This would broaden the scope and capabilities of PRONTO beyond prototyping, to the design and analysis in engineering and architecture. We would also like to enhance the expressive qualities of animations by drawing insights from the rich literature of performance and sketch-based animation tools in HCI and graphics [25, 54]. Beyond animations, supporting annotations, commenting, reviewing, recapturing the video without losing the sketches, and collaboration would significantly enhance the capabilities of PRONTO. Validating these ideas is an exciting future work direction that would further expand the scope of contextual prototyping and ideation.

"
Student Engagement in Sensitive Design Contexts: A Case Study in Dementia Care,https://dl.acm.org/doi/10.1145/3313831.3376161,"
There is a growing body of HCI work that seeks to understand and enhance the lived experience of people with dementia. The majority of this work involves researchers working alongside people with dementia and their carers, focused on the design project outcomes. In order to enrich the social context of this work, we explore broadening participation to include student volunteers. To encourage mutually engaging experiences in this design context, careful consideration of how to support both students and people with dementia is needed. In this paper, we present two case- studies of co-design projects between students and people with dementia. Our findings detail the use of design methods to reconfigure the role of the residents in care contexts and the students learning process. We discuss the project learning outcomes as well as practical and ethical considerations to support the use of design methods to support mutual engagement in sensitive contexts. This paper describes the enriching social engagement which can be supported through design processes in dementia care. Our findings convey the nature of mutually engaged learning between students and people with dementia, and the ways in which design can reconfigure roles in clinical and educational settings. We suggest that careful planning of design projects, in which the abilities of both groups of participants are supported, provides a solid base for ensuring that students are key figures in broadening design participation in dementia care.
"
"Social Acceptability in HCI: A Survey of Methods, Measures, and Design Strategies",https://dl.acm.org/doi/10.1145/3313831.3376162,"
With the increasing ubiquity of personal devices, social acceptability of human-machine interactions has gained relevance and growing interest from the HCI community. Yet, there are no best practices or established methods for evaluating social acceptability. Design strategies for increasing social acceptability have been described and employed, but so far not been holistically appraised and evaluated. We offer a systematic literature analysis (N=69) of social acceptability in HCI and contribute a better understanding of current research practices, namely, methods employed, measures and design strategies. Our review identified an unbalanced distribution of study approaches, shortcomings in employed measures, and a lack of interweaving between empirical and artifact-creating approaches. The latter causes a discrepancy between design recommendations based on user research, and design strategies employed in artifact creation. Our survey lays the groundwork for a more nuanced evaluation of social acceptability, the development of best practices, and a future research agenda. In this work, we reviewed papers on social acceptability in HCI. During the nearly 20 years covered by our analysis, a significant amount of contributions to a better understanding of social acceptability (and impression management) in HCI were made. However, we also identified gaps in the distribution of research approaches. In particular, ethnography, participatory design and field research in naturalistic settings without the researcher’s presence were only sparsely employed. Moreover, we showed that the consideration of social acceptability is not yet interwoven with the whole design process: results from empirical work on social acceptability do not propagate to the creation of socially acceptable designs or prototypes. Last but not least, we discussed the current lack of established, standardized questionnaires quantifying social acceptability in a non-proxied fashion, and highlight the need to develop differentiated and truly operational measures. We hope to inspire more discussions about what constitutes social acceptability in HCI [57, 58], what constructs it might comprise (e.g., “coolness” [18, 97]), and how design activities can be proactively oriented toward influencing social acceptability.
"
Does Smartphone Use Drive our Emotions or vice versa? A Causal Analysis,https://dl.acm.org/doi/10.1145/3313831.3376163,"
In this paper, we demonstrate the existence of a bidirectional causal relationship between smartphone application use and user emotions. In a two-week long in-the-wild study with 30 participants we captured 502,851 instances of smartphone application use in tandem with corresponding emotional data from facial expressions. Our analysis shows that while in most cases application use drives user emotions, multiple application categories exist for which the causal effect is in the opposite direction. Our findings shed light on the relationship between smartphone use and emotional states. We furthermore discuss the opportunities for research and practice that arise from our findings and their potential to support emotional well-being. In this work, we investigate the bidirectional causal relationship between the emotional state of users and their phone use. Our results show that for some participants, the use of particular apps causes them to experience certain emotions; however, for other participants, their emotions drive app use behaviour. We also found noticeable differences between different application categories with regards to their causal relationship with the users’ emotional state. These quantitative findings corresponded with qualitative results showing that participants mentioned that certain applications cause them to experience certain emotions, and that feeling certain emotions led them to use certain applications. Our findings are a step towards building personalised models which can help users better understand the relationship between their phone use is intertwined with their emotional states. This could potentially lead to more effective decision-making with regards to smartphone use as well as better technology-mediated support for emotion regulation.
"
EAST: Early Autism Screening Tool for Preschoolers,https://dl.acm.org/doi/10.1145/3313831.3376164,"
We describe the iterative co-design process and evaluation of an early autism screening tool (EAST). EAST is an intermediary interactive tablet based app that assists in the early-detection of Autism Spectrum Disorder (ASD) by screening preschoolers in Pakistan through play-based activities in a home, school or clinical setting. Medical professionals, parents of autistic children and teachers were surveyed through focus groups to understand the reasons that contribute to the increasing number of missed early detections, and late- or misdiagnoses. We also evaluate the acceptability, usability and validity of our tool. We tested EAST with both typically developed and autistic children on how they relate to people, imitation, motor skills, visual and intellectual response. They were scored via time taken, the number of wrong attempts, or incorrect answers and audiovisual feedback. This paper contributes towards a digital autism screening tool that delivers insights into the child's behaviour and enables collaboration among parents, teachers and medical professionals. In conclusion, we have built a better understanding of the problem and improved the acceptance and validity of a digital tool. We co-designed a usable, efficient, engaging, and interactive platform that will assist in early detection of ASD through screening preschoolers in a home, school or clinical environment and ensured collaboration among stakeholders. The next phase will see us getting our tool validated through a clinical trial by involving general practitioners who are the first point of contact. Our tool can correspondingly act as a measure of yearly progress of the child in specific areas by keeping track of the child’s performance. We plan to conduct a cross-cultural study (in the Middle East) to establish validation of EAST universally. Furthermore, it can also be mapped onto screening other developmental disorders and learning disabilities.
"
Why Johnny Can't Unsubscribe: Barriers to Stopping Unwanted Email,https://dl.acm.org/doi/10.1145/3313831.3376165,"
A large proportion of email messages in an average Internet user's inbox are unwanted commercial messages from mailing lists, bots, and so on. Although such messages often include instructions to unsubscribe, people still struggle with stopping unwanted email. We investigated the user experience of unsubscribing from unwanted email messages by recruiting 18 individuals for via a lab study followed by semi-structured interviews. Based on unsubscribing practices of the study participants, we synthesized eight common unsubscription mechanisms and identified the corresponding user experience challenges. We further uncovered alternative practices aimed at circumventing the need to unsubscribe. Our findings reveal frustration with the prevailing options for limiting access to the self by managing email boundaries. We apply our insight to offer design suggestions that could help commercial providers improve the user experience of unsubscribing and provide users more control over the email they receive. Users struggle to manage unwanted email, leaving them with a sense of decreasing control over their inboxes. Even though participants in our study were relatively familiar with the process of unsubscribing, user experience issues prevented effective use of available mechanisms to establish and assert effective email boundaries. The barriers to unsubscribing uncovered in our study underscore the need for increased attention by commercial entities and email providers to making unsubscribing truly functional for end users.
"
Making Chat at Home in the Hospital: Exploring Chat Use by Nurses,https://dl.acm.org/doi/10.1145/3313831.3376166,"
In this paper, we examine WhatsApp use by nurses in India. Globally, personal chat apps have taken the workplace by storm, and healthcare is no exception. In the hospital setting, this raises questions around how chat apps are integrated into hospital work and the consequences of using such personal tools for work. To address these questions, we conducted an ethnographic study of chat use in nurses' work in a large multi-specialty hospital. By examining how chat is embedded in the hospital, rather than focusing on individual use of personal tools, we throw new light on the adoption of personal tools at work — specifically what happens when such tools are adopted and used as though they were organisational tools. In doing so, we explicate their impact on invisible work [77] and the creep of work into personal time, as well as how hierarchy and power play out in technology use. Thus, we point to the importance of looking beyond individual adoption by knowledge workers when studying the impact of personal tools at work. In describing the use of chat in nurses’ work, we drew attention to a number of ways chat is made at home in the hospital. A notable difference between our research and most previous research into chat ( [7,35,59] being notable exceptions) is that by taking an ethnographic approach and examining closely how chat is embedded in the ongoing work of the organisation, we explicate how chat is used to accomplish that work and the consequences of its use for workers. We complicated the idea of worker-driven adoption, by showing how WhatsApp is used as though it were an organisational tool. By examining how chat bridges the spatial and temporal rhythms of nurses’ work, we highlight the tension between doing nursing and the other work of being a nurse, and how chat brings the hospital home. Interestingly, if chat were to be made an organisational tool, this invisible work would be made visible in the organisation. As the use of chat and other personal tools increases in organisations, this has implications beyond knowledge workers and professionals in the Global North. We must also understand the impacts on hourly and care workers (such as nurses), whose work is often of a different nature and must be recognized, whether it is physical or digital.
"
The Politics of Privacy Theories: Moving from Norms to Vulnerabilities,https://dl.acm.org/doi/10.1145/3313831.3376167,"
Privacy and surveillance are central features of public discourse around use of computing systems. As the systems we design and study are increasingly used and regulated as potential instruments of surveillance, HCI researchers-even those whose focus is not privacy-find themselves needing to understand privacy in their work. Concepts like contextual integrity and boundary regulation have become touchstones for thinking about privacy in HCI. In this paper, we draw on HCI and privacy literature to understand the limitations of commonly used theories and examine their assumptions, politics, strengths, and weaknesses. We use a case study from the HCI literature to illustrate conceptual gaps in existing frameworks where privacy requirements can fall through. Finally, we advocate vulnerability as a core concept for privacy theorizing and examine how feminist, queer-Marxist, and intersectional thinking may augment our existing repertoire of privacy theories to create a more inclusive scholarship and design practice. We are witnessing the migration of vulnerable privacy concerns into the mainstream suggesting precisely this point that privileged privacy that serves one end is used to exploit a whole class of individual. For instance, the simple technology used to stalk IPV victims is the very same technology used by parents to track their children [17]. These are technologies that have mainstream legitimate use and thus are slowly becoming the norm. Identity and political discourse may be critical to how service providers design for privacy and how users conceive of privacy. This is a departure from individualism as well as normative frames, both of which we have shown to be entangled in ways that reinforce heteronormative, privileged identity discourse and notions of territory. Predicting information flows based on expectations is problematic—in large part because companies collect our data and we have no voice in how much and to whom it is given. The privacy violations affecting vulnerable identities are surfacing the problematic nature of our relationship to privacy design and technologies that are unregulated or part of services to the extent that they make attacks possible by people with no technical abilities, or who simply use those technologies and services. The convergence of social, economic, and identitybased disadvantages exacerbates harms by advertisers and governments. Facebook algorithms predict, for example, gender, ethnicity, and sexual orientation, based on user liking and friending behavior [52, 56]. Loan and job algorithms “learn” to identify women and minorities using otherwise obscure identity proxies like shopping habits or keywords. Moreover, our expectations have been constantly put to the test by continuous data breaches and the understanding that we are always sharing our data with technology companies and institutions. Individualism assumes that people have equal voice in articulating their privacy and defending it when we know that not to be the case. Normative approaches tend to overlook especially the fact that vulnerable individuals do not have a voice in what is agreed upon to be appropriate levels of privacy. Intersectional identity frames how people behave in the context of social structures, and how those structures stifle expression and free movement. When looking at norm-based theories, it is important to consider the political theories, cultures, classes, and systems to which they are moored. Norm-based theories of privacy draw on collectivism. But what are we to make of norms produced in cultures where the politics (or political goals) are dramatically different? We need to acknowledge that there are competing norms—in some cases to achieve the same ends—and only some norms are articulated in the system. This is because norm-based theories are grounded in shared understanding of only those with legitimate access to these platforms. Contexts reflect a world of privilege in design and discourse, and thus require identity- and political-based approaches. Intersectional frames bring together identities and structures of power and queer-Marxism a “material matrix” and politics of identity; together, we argue, they are best-equipped to deal with this privacy landscape. Positionality Both authors are privacy researchers with a critical orientation to this space. To adopt and practice intersectionality or critical identity theory, one has to come to terms with their own positionality. As white women scholars who are neither black nor queer, we acknowledge that our role in pointing out where our privacy theories are potentially hegemonic and oppressive, while perhaps helpful, is also problematic. For instance, we take care to credit our ideas to the scholars on whom our work is built, to translate our ideas to concrete suggestions, and to be wary of how our own efforts to contribute may perpetuate the very problems we are seeking to expose and solve: erasure or marginalization, complexity of lived experiences, and the role of norms and power in subjugating vulnerable people.
"
What is this URL's Destination? Empirical Evaluation of Users' URL Reading,https://dl.acm.org/doi/10.1145/3313831.3376168,"
Common anti-phishing advice tells users to mouse over links, look at the URL, and compare to the expected destination, implicitly assuming that they are able to read the URL. To test this assumption, we conducted a survey with 1929 participants recruited from the Amazon Mechanical Turk and Prolific Academic platforms. Participants were shown 23 URLs with various URL structures. For each URL, participants were asked via a multiple choice question where the URL would lead and how safe they feel clicking on it would be. Using latent class analysis, participants were stratified by self-reported technology use. Participants were strongly biased towards answering that the URL would lead to the website of the organization whose name appeared in the URL, regardless of its position in the URL structure. The group with the highest technology use was only minorly better at URL reading. Being able to accurately compare a URL to an expected destination is an important skill needed in detecting fraudulent URLs, such as those sent in phishing communications. Our findings clearly illustrate that participants, even those with extensive computer experience, are unable to accurately predict the destinations of relatively simple and trick-free URLs. Instead of recognising that URLs typically go to the organization listed in the domain position, our participants tended to select the recognisable organization name in the URL, even if it was located in non-domain positions, such as the subdomain. However, users were not necessarily consistent in their URL reading approaches, with only 32.2% consistently selecting the organization name and 8.1% consistently selecting the domain. Technology use impacted their ability to correctly read URLs, but the impact was fairly low, with mobile users correctly answering only 15.9% of the questions with the organization in the subdomain, and power users only 25.4%. The results are concerning as they indicate that even technically skilled users struggle to accurately predict the destination of a basic URL. Participants were more likely to rate a URL as safe to click on if they thought that its destination was the organisation named in the URL. They were also more dubious of short URLs than the domain URLs, single subdomain URLs, and complex URLs. This result is somewhat good as it indicates that users can identify that the destinations of short URLs are more difficult to predict than the destinations of longer ones.

"
"""Arseing around was Fun!"" – Humor as a Resource in Design and Making",https://dl.acm.org/doi/10.1145/3313831.3376169,"
Humor is an inevitable part of human life. Most of us are capable of experiencing and appreciating humor. From this perspective, surprisingly little HCI research can be found scrutinizing the existence, role, and potential of humor in our design practice. The gap remains also related to children and teenagers; there is a lack of studies appreciating the emergence and existence of humor in the design process without intentionally evoking it. Thus, this study examines humor as a naturally occurring phenomenon in the design process. The study was conducted in collaboration with a class of teenagers and their teachers. The study identifies various forms and functions of humor in the design process and reveals its situated, emergent nature as a resource in interaction within design. The study proposes a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as an interactional resource in design. Surprisingly little HCI research can be found scrutinizing the existence, role and potential of humor in our design practice, approaching humor as a mundane phenomenon in human interaction. This gap also remains in research related to children and teenagers. This study examined humor as naturally occurring in the design process with teens. The study was conducted in collaboration with a local school: with a class of teenagers and their teachers interested in innovation, design and Making education. The study identified various forms and functions of humor in the design process and revealed its situated, emergent nature as a resource in interaction. The study identified interesting implications for HCI research and design. The study emphasized the integral role of humor in all human activity, including design and Making, Humor enables addressing delicate issues, while a lot of sensitivity is needed concerning the fine line between humor and bullying. The study concluded by arguing for the importance of: 1) supporting and facilitating benign forms of humor in the classroom for purposes such as group cohesion, stress relief, facework, and impression management; 2) approaching the classroom as a complex microcosmos that requires a careful study before engaging in practical design and Making activities; and 3) a self-reflective as well as a responsible, ethical stance towards one’s own role in cultivating humor and towards the multifarious nature of humor in the classroom. As a result, a practical tool for designers for anticipating and potentially facilitating the emergence, forms and usages of humor as a resource in interaction was proposed. As for the limitations of the study, this analysis shed light on a design and Making project in a Finnish school with a particular class of teenagers. The power relationships and interaction orders that were natural in that particular environment of pedagogic culture are not generalizable to any context. These results were gained with one specific class, in which the participants were familiar with each other, but into which an unfamiliar research team entered. Our situational approach sees humor as a resource in interaction, in which there always is a complex constellation of participants involved and the emergence, forms and usages of humor depend on that. With different kind of constellation of participants, differences can be expected. We particularly point out that cultural aspects (broadly interpreted) need to be recognized, and in several senses. The participants in our study had a shared cultural background in many respects: they were pupils from one class, they knew each other and their teachers, they had quite a similar background as teenagers in Oulu, Finland. Definitely this background influences what is considered humor, the forms it takes and the roles it plays. The research team also had a shared cultural background with the study participants, while only to an extent. Even if they have children of the age and some of them also extensive experience as teachers of the age group, there for sure are many aspects of humor that remained unrecognized due to differences in terms of age and, consequently, communities and related discourses. We were able to recognize and interpret many aspects (e.g. memes, language games), while we certainly remained ignorant about others. However, this is not critical as we did not aim to comprehensively capture and classify all instances of humor but rather to understand how it functions as a resource in interaction, the strength of our analysis being in shedding light on the complexity involved. We utilized the versatile, multimodal research material and in-depth collaborative data analysis to ensure the trustworthiness of our interpretations. Despite the limitations, we maintain that the results are valuable in other HCI contexts as well, particularly in groupwork situations. Humor is an inevitable part of human life in general and it acts as a resource in interaction among people of all kinds. With different kinds of participants in groupwork, be it related to design, making, or research on HCI, one may expect the emergence of humor as a resource – with adults and children, at work and during leisure time, with people familiar to each other as well as with strangers, in familiar everyday settings as well as in unfamiliar places and spaces. Studies exploring the topic in different cultural settings and with differing age groups are warmly welcomed. Future research is also needed to provide an even more detailed account of humor as a multimodal resource to see how the interactions unfold moment by moment in design and Making activities. Based on our results, we recommend directing special attention to the phases critical from the perspective of the emerging design concept and product. In sum, we advocate the situated perspective on humor. This entails exploring how humor emerges as a resource for participants in situ, rather than looking for instances of humor for categorization without context. Through a detailed analysis of data, we illustrated how humor, indeed, acted as such a resource. Humor was used in building identification, affiliation, mutual relationships and cohesion among the participants. It was also employed as a resource for facework and impression management among pupils engaging with their own familiar class and teachers but also with unfamiliar adult researchers. It was also found to be used in the legitimation of the design ideas and contributing to negotiations of competence and division of labor in an uncertain situation, as the pupils faced a design and Making project for the first time, in a way balancing between “being serious” and “arseing around”.
"
Understanding the Care Ecologies of Veterans with PTSD,https://dl.acm.org/doi/10.1145/3313831.3376170,"
Post-traumatic stress disorder (PTSD) disproportionately affects United States veterans, yet they may be reluctant to seek or engage in care. We interview 21 participants, including veterans with PTSD, clinicians who treat veterans and friends and family that support veterans through mental health ordeals. We investigate the military identity these veterans share. We explore how this may add to their reluctance in care-seeking behaviors. We also explore the roles of human and non-human intermediaries in ecologies of care and the potential for enhancing patient empowerment in current clinical treatment contexts. We discuss how military culture can be utilized in clinical care, how multiple perspectives can be leveraged to create a more holistic view of the patient, and finally, how veterans can be empowered during treatment. We conclude with recommendations for the design of sociotechnical systems that prioritize the above in support of the mental well-being of veterans with PTSD. HCI is increasingly investigating complex ecologies of care and the importance of patient empowerment. We extended this work by focusing on barriers to therapeutic care among veterans with PTSD and exploring what role technology might play in enhancing empowerment. Drawing on qualitative research inquiry, we uncovered the challenges and opportunities in care-seeking for veterans with PTSD. We discussed how the veterans’ military identity might lead us to enriched design opportunities. Future design would likely benefit from leveraging the presence of partial caring perspectives owing to additional human and non-human intermediaries, with the understanding that the veteran must be at the center of the design activity.
"
"Self-Expression by Design: Co-Designing the ExpressiBall with Minimally-Verbal Children
                     on the Autism Spectrum",https://dl.acm.org/doi/10.1145/3313831.3376171,"
Expressing one's thoughts and feelings is a fundamental human need - the basis for communication and social interaction. We ask, how do minimally-verbal children on the autism spectrum express themselves? How can we better recognise instances of self-expression? And how might technologies support and encourage self-expression? To address these questions, we undertook co-design research at an autism-specific primary school with 20 children over one school year. This paper contributes six Modalities of Self-Expression, through which children self-express and convey their design insights. Each modality of self-expression can occur across two different dimensions (socio-expressive and auto-expressive) and can be of a fundamental or an integrative nature. Further, we contribute the design trajectory of a tangible ball prototype, the ExpressiBall, which - through voice, sounds, lights, and motion sensors - explores how tangible technologies can support this range of expressive modalities. Finally, we discuss the concept of Self-Expression by Design. Minimally-verbal children’s inclusion and participation is often limited in co-design, as many practices focus on verbal collaboration. We investigated how minimally-verbal children on the autism spectrum express themselves, in order to understand how to better include them in co-design. We found that children are continually self-expressing through modalities of Words, Sounds, Bodily Movements, Touch and Gesture, Creativity and Play. We propose these six modalities of auto- and socio-expression, as a means of tuning into and identifying how a child self-expresses. We contributed a design case study of the ExpressiBall, a playful tangible ball technology, arguing that multimodal forms of technology are needed to support self-expression for this group. Self-expression can be fluid, changing, and highly individualised. By learning to identify and support different modalities of self-expression, the researcher or designer can equip themselves with the ability to understand design contributions beyond the verbal, while also supporting agency and choice in participatory contexts.
"
DataQuilt: Extracting Visual Elements from Images to Craft Pictorial Visualizations,https://dl.acm.org/doi/10.1145/3313831.3376172,"
Recent years have seen an increasing interest in the authoring and crafting of personal visualizations. Mainstream data analysis and authoring tools lack the flexibility for customization and personalization, whereas tools from the research community either require creativity and drawing skills, or are limited to simple vector graphics. We present DataQuilt, a novel system that enables visualization authors to iteratively design pictorial visualizations as collages. Real images (e.g., paintings, photographs, sketches) act as both inspiration and as a resource of visual elements that can be mapped to data. The creative pipeline involves the semi-guided extraction of relevant elements of an image (arbitrary regions, regular shapes, color palettes, textures) aided by computer vision techniques; the binding of these graphical elements and their features to data in order to create meaningful visualizations; and the iterative refinement of both features and visualizations through direct manipulation. We demonstrate the usability of DataQuilt in a controlled study and its expressiveness through a collection of authored visualizations from a second open-ended study. Inspired by a vision of data ubiquity and freedom of expression, this work presented DataQuilt, a tool to support the creation of rich and organic visualizations, by borrowing and repurposing elements from raster images. This makes visualization authoring accessible to a broader audience that is not necessarily artistically inclined, nor versed in image editing software and visualization programming. Our design process was heavily user centered: DataQuilt was informed by formative findings from two data driven workshops, and was validated in both a usability study and a creative, free-form exercise study. We found that the tool can be easily appropriated by novices and is expressive enough to allow for significant diversity in visualization designs. More importantly, we found that the tool supported quick exploratory manipulations of designs, which has been noted by some participants as being conducive to creativity. From emerging gaps we have also outlined an agenda for future research. We underscore the importance of improving the expressiveness of bindings to size (beyond vertical bar charts), color (e.g., applying color to parts of the glyph, instead of painting the entire region a flat color) and of positioning (e.g., for spatial clustering). More generally, findings from the formative assessment and evaluation studies revealed great user interest in powerful authoring tools for custom visualizations, that remain nonetheless easy to use and conductive to design refinement and experimentation in order to support creativity.

"
EYEditor: Towards On-the-Go Heads-Up Text Editing Using Voice and Manual Input,https://dl.acm.org/doi/10.1145/3313831.3376173,"
On-the-go text-editing is difficult, yet frequently done in everyday lives. Using smartphones for editing text forces users into a heads-down posture which can be undesirable and unsafe. We present EYEditor, a heads-up smartglass-based solution that displays the text on a see-through peripheral display and allows text-editing with voice and manual input. The choices of output modality (visual and/or audio) and content presentation were made after a controlled experiment, which showed that sentence-by-sentence visual-only presentation is best for optimizing users' editing and path-navigation capabilities. A second experiment formally evaluated EYEditor against the standard smartphone-based solution for tasks with varied editing complexities and navigation difficulties. The results showed that EYEditor outperformed smartphones as either the path OR the task became more difficult. Yet, the advantage of EYEditor became less salient when both the editing and navigation was difficult. We discuss trade-offs and insights gained for future heads-up text-editing solutions. We presented EYEditor, a novel heads-up, smartglass-based text-editing solution optimized for on-the-go use cases with a combination of voice and manual input. An iterative design process with two controlled experiments gained us the following insights as take-away messages: 1) text content should be presented visually, sentence-by-sentence to optimize users’ text-correction and path-navigation capabilities on the go; 2) overlapping audio and visual output (reading-while-listening) or overloading the screen space with text is highly distracting for on-the-go text-editing and should be avoided; 3) our hybrid solution supports mobility while text-editing better than typing on a smartphone for more complex paths/tasks, until users’ attention span reaches a limit. In conclusion, our paper takes a significant step forward in understanding how to design heads-up interactions for on-the-go text-editing. This is also our first step to establish the feasibility, desirability and viability of using smart glasses as an interactive platform in on-the-go scenarios.

"
"""No powers, man!"": A Student Perspective on Designing University Smart Building Interactions",https://dl.acm.org/doi/10.1145/3313831.3376174,"
Smart buildings offer an opportunity for better performance and enhanced experience by contextualising services and interactions to the needs and practices of occupants. Yet, this vision is limited by established approaches to building management, delivered top-down through professional facilities management teams, opening up an interaction-gap between occupants and the spaces they inhabit. To address the challenge of how smart buildings might be more inclusively managed, we present the results of a qualitative study with student occupants of a smart building, with design workshops including building walks and speculative futuring. We develop new understandings of how student occupants conceptualise and evaluate spaces as they experience them, and of how building management practices might evolve with new sociotechnical systems that better leverage occupant agency. Our findings point to important directions for HCI research in this nascent area, including the need for HBI (Human-Building Interaction) design to challenge entrenched roles in building management. We presented a study of student occupants of a smart building, resulting in new understandings of how HCI and HBI practitioners might design interactions that foster agency and participation in facilities management processes. Findings from a qualitative processincluding a building walk and speculative design workshop led to new understandings of students’ situated experiences within the smart building, and socio-organisational concerns for the design of HBI. We suggest new directions for the HCI and HBI fields in this area, including an open challenge for future work to disrupt existing service-oriented structures in facilities management.
"
"""I Hear You, I Feel You"": Encouraging Deep Self-disclosure through a Chatbot",https://dl.acm.org/doi/10.1145/3313831.3376175,"
Chatbots have great potential to serve as a low-cost, effective tool to support people's self-disclosure. Prior work has shown that reciprocity occurs in human-machine dialog; however, whether reciprocity can be leveraged to promote and sustain deep self-disclosure over time has not been systematically studied. In this work, we design, implement and evaluate a chatbot that has self-disclosure features when it performs small talk with people. We ran a study with 47 participants and divided them into three groups to use different chatting styles of the chatbot for three weeks. We found that chatbot self-disclosure had a reciprocal effect on promoting deeper participant self-disclosure that lasted over the study period, in which the other chat styles without self-disclosure features failed to deliver. Chatbot self-disclosure also had a positive effect on improving participants' perceived intimacy and enjoyment over the study period. Finally, we reflect on the design implications of chatbots where deep self-disclosure is needed over time. In this study, we conducted a three-week study to investigate how self-disclosure of chatbots affects users’ self-disclosure behavior. Both conversation styles and the time elapsed since the start of the experiment influenced users’ subjective experiences of using the chatbot and their objective selfdisclosure behavior. In general, the chatbot that made its own self-disclosures performed better at facilitating its users’ selfdisclosures in response to sensitive questions, successfully encouraging users to provide longer responses and express deeper thoughts and feelings on sensitive topics. However, this effect might only be applicable to sensitive questions, insofar as in the case of journaling, answer length decreased and fewer feelings were disclosed as time went by.
"
"CARoma Therapy: Pleasant Scents Promote Safer Driving, Better Mood, and Improved Well-Being
                     in Angry Drivers",https://dl.acm.org/doi/10.1145/3313831.3376176,"
Driving is a task that is often affected by emotions. The effect of emotions on driving has been extensively studied. Anger is an emotion that dominates in such investigations. Despite the knowledge on strong links between scents and emotions, few studies have explored the effect of olfactory stimulation in a context of driving. Such an outcome provides HCI practitioners very little knowledge on how to design for emotions using olfactory stimulation in the car. We carried out three studies to select scents of different valence and arousal levels (i.e. rose, peppermint, and civet) and anger eliciting stimuli (i.e. affective pictures and on-road events). We used this knowledge to conduct the fourth user study investigating how the selected scents change the emotional state, well-being, and driving behaviour of drivers in an induced angry state. Our findings enable better decisions on what scents to choose when designing interactions for angry drivers. It is dangerous to feel angry while driving a car. Anger leads to aggressive driving behaviour [21] and crashes [26]. The 2018 data from the National Highway Traffic Safety Administration (NHTSA) [48] suggests that 94% of all road traffic accidents are caused by driver error. 33% of such accidents could be linked to behaviours associated with road rage (e.g. driving too fast, illegal manoeuvre). Therefor, a strategy for changing anger to a positive or neutral emotion might become crucial in reducing the number of accidents. Our findings suggest that pleasant scents (such as rose and peppermint) could be able to shift the emotion of the driver towards the positive valence. However, in terms of well-being, it would be necessary to customise the choice based on the driver’s preferences. From its properties, the scent of peppermint is more arousing than rose, however, our interview data provides hints that some people might find it calming, as peppermint is associated with comforting experiences. In terms of driving behaviour, our findings show that an unpleasant scent (i.e. civet) might not be a good choice for stimulating angry drivers, as it results in a significantly higher number of collisions. On the contrary, pleasant scents of rose and peppermint could be able to help calm the driver down.
"
Understanding and Visualizing Data Iteration in Machine Learning,https://dl.acm.org/doi/10.1145/3313831.3376177,"
Successful machine learning (ML) applications require iterations on both modeling and the underlying data. While prior visualization tools for ML primarily focus on modeling, our interviews with 23 ML practitioners reveal that they improve model performance frequently by iterating on their data (e.g., collecting new data, adding labels) rather than their models. We also identify common types of data iterations and associated analysis tasks and challenges. To help attribute data iterations to model performance, we design a collection of interactive visualizations and integrate them into a prototype, Chameleon, that lets users compare data features, training/testing splits, and performance across data versions. We present two case studies where developers apply \system to their own evolving datasets on production ML projects. Our interface helps them verify data collection efforts, find failure cases stretching across data versions, capture data processing changes that impacted performance, and identify opportunities for future data iterations. In this paper, we explored the practice of data iteration in production machine learning. We conducted formative research through interviewing 23 applied ML developers across 13 teams at Apple. We identified a set of tasks and challenges practitioners face to tackle changing datasets. We then designed and developed a set of interactive visualizations integrated into a prototype tool that supports these tasks. We demonstrated the tool’s effectiveness on two case studies where model developers applied the interface to their own evolving datasets used in production ML projects. We hope this work emphasizes the importance of designing data as equally important as designing models in the ML process, inspiring future research and tooling around evolving data.

"
Is This An Ad?: Automatically Disclosing Online Endorsements On YouTube With AdIntuition,https://dl.acm.org/doi/10.1145/3313831.3376178,"
Undisclosed online endorsements on social media can be misleading to users who may not know when viewed content contains advertisements. Despite federal regulations requiring content creators to disclose online endorsements, studies suggest that less than 10% do so in practice. To overcome this issue, we need knowledge of how to best detect online endorsements, knowledge about how prevalent online endorsements are in the wild, and ways to design systems to automatically disclose advertising content to viewers. To that end, we designed, implemented, and evaluated a tool called AdIntuition which automatically discloses when YouTube videos contain affiliate marketing, a type of social media endorsement. We evaluated AdIntuition with 783 users using a survey, field deployment, and diary study. We discuss our findings and recommendations for future measurements of and tools to detect and alert users about affiliate marketing content. In this paper, we presented new ways to detect and measure affiliate marketing content on YouTube and a tool for automatically disclosing this content to users on the platform. We also presented findings from evaluating the tool, AdIntuition which suggest that the detection techniques are performing reasonably well and that users are able to better identify advertising content with AdIntuition’s automatic disclosures. Based on our findings, we recommend that future studies extend our work to build more robust online automatic ad detection tools to keep users informed about the content they are viewing.

"
"Unplatformed Design: A Model for Appropriating Social Media Technologies for Coordinated
                     Participation",https://dl.acm.org/doi/10.1145/3313831.3376179,"
Using existing social media technologies as a resource for design offers significant potential for sustainable and scalable ways of coordinating participation. We look at three exemplar projects in three distinct domains that have successfully coordinated participation through the configuration and augmentation of existing social media technologies: participatory future forecasting, participatory health research, and connectivist learning. In this paper we conceptualise social media technologies as material for design, that is, as the raw material with which coordinated participation is realized. From this we develop a model that proposes four material qualities of social media technologies, morphology, role, representation of activity and permeability, and point to how they can be productively employed in the design of coordination of participation. We have presented a model for the unplatformed design of coordinated participation. The model consists of a conceptualization of social media technologies as a design material, with four material qualities morphology, role, representation of activity and permeability and the ways in which they can be manipulated through configuration, hard augmentation and soft augmentation. We have demonstrated the utility of this model from our investigation of three case studies of coordinated participation, and have pointed to the implications of unplatformed design as drawing attention to new resources for design around the appropriation of existing social media technologies, which may have ramifications on both the design of these technologies and on the design of coordinated participation going forward.
"
DoughNets: Visualising Networks Using Torus Wrapping,https://dl.acm.org/doi/10.1145/3313831.3376180,"
We investigate visualisations of networks on a 2-dimensional torus topology, like an opened-up and flattened doughnut. That is, the network is drawn on a rectangular area while ""wrapping"" specific links around the border. Previous work on torus drawings of networks has been mostly theoretical, limited to certain classes of networks, and not evaluated by human readability studies. We offer a simple interactive layout approach applicable to general graphs. We use this to find layouts affording better aesthetics in terms of conventional measures like more equal edge length and fewer crossings. In two controlled user studies we find that torus layout with either additional context or interactive panning provided significant performance improvement (in terms of error and time) over torus layout without either of these improvements, to the point that it is comparable to standard non-torus layout. Our studies indicate that torus layout could be a practical technique (not worse than standard graph visualisation techniques) for the tasks tested, but that either redundant context or interactive panning are necessary. The graphs tested were automatically generated using algorithms designed to simulate naturally occurring graphs, but we would like to further evaluate the torus representations in a real-world application and see if it is usable by domain experts. We recognise that testing other types of tasks (such as cluster identification) on larger graphs is an important next step - but it is beyond the scope of this initial study which focuses on precise graph readability and path/edge following. We would also like to see if torus drawing works well for graphs larger than those in our studies (the largest had 15 nodes and 36 edges). We hope that the reduced clutter torus diagrams may work well for tasks particularly important to large networks, and those with complex structures that can benefit from a relaxation of the structure and less line crossings. Technically speaking, our stress-minimising torus layout method is the first method we are aware of that is able to layout all graphs (not just graphs limited to a particular genus) on a torus topology. While we can force it to converge we cannot make strong guarantees that it converges to a local optimum. The interactive nature of the algorithm means that a user can guide it to a quite reasonable layout, certainly layouts that were good enough for our study. However, we are interested to see if the combinatorial techniques for layout of restricted classes of graphs on the torus, can be adapted to help us find good starting conditions for our stress-minimising torus layout in order to create a robust and completely autonomous high-quality torus layout.

"
"Addressing Cognitive and Emotional Barriers in Parent-Clinician Communication through
                     Behavioral Visualization Webtools",https://dl.acm.org/doi/10.1145/3313831.3376181,"
Effective communication between clinicians and parents of young children with developmental delays can decrease parents' anxiety, help them handle bad news, and improve their adherence to proposed interventions. However, parents have reported dissatisfaction regarding their current communication with clinicians, and they face cognitive and emotional challenges when discussing their child's developmental delays. In this paper, we present visualization as a facilitator of parent-clinician communication and how it could address existing communication challenges. Parents and clinicians anticipated visualization webtools would aid their communication by helping parents gain a better understanding of their child, acting as objective evidence, and highlighting the strength of the child as well as important medical concepts. In addition, visualization can act as a longitudinal record, helping parents track, explore, and share their child's developmental progress. Finally, we propose visualization as a tool to guide parents in their transition from feeling emotional and disempowered to advocating with confidence. While effective parent-clinician communication on developmental delay is important, parents experience an emotional strain as they discuss hopes and fears, developmental concerns, and feelings of distress. In addition to the emotional strain, parents also experience a cognitive burden due to medical jargon or presentation of data that is inaccessible to them. In this paper, we presented data visualization webtools as a method of facilitating parent-clinician communication that could address these communicative challenges. Parents and clinicians responded positively to the idea of using visualizations in their conversations and suggested three ways in which they would be useful. Two additional roles of visualization in clinical settings were discussed – acting as a longitudinal record of the child’s development and preserving privacy while sharing behavioral data with others. We conclude by suggesting how visualizations could be used in clinical communication while preventing misinformation, and how visualization could empower parents in their journey from dealing with emotions to actively advocating for their child.

"
"""On Finsta, I can say 'Hail Satan'"": Being Authentic but Disagreeable on Instagram",https://dl.acm.org/doi/10.1145/3313831.3376182,"
We use personality theory to compare self-presentation between multiple Instagram accounts, investigating authenticity and consistency. Many studies claim social media promote inauthentic self-presentation focused on socially desirable traits. At the same time, affordances suggest that self-presentation should be relatively consistent within one social medium. For 88 participants, we examine personality traits for 'real Instagram' ('Rinsta') versus 'fake Instagram' ('Finsta') accounts, comparing these with people's offline traits using mixed-methods. Counterintuitively, we find Finsta accounts often present socially undesirable traits. Furthermore, different accounts on the same social medium reveal quite different styles of self-presentation. Overall Finstas are more Extraverted, less Conscientious, and less Agreeable than Rinstas, although equally Neurotic as offline. Interviews indicate trait differences arise from differing audience perceptions. A large anonymous Rinsta audience promotes a carefully curated self. In contrast, a small but trusted Finsta audience can engender more authentic, but negative self-presentation. We discuss design and theory implications. We find large, reliable personality differences between different profiles on Instagram and Offline. On Rinsta, people perceive their personality as less Neurotic and Extraverted, presenting a positively curated version of themselves. On Finsta, people see their personality as more Extraverted and Neurotic, but less Agreeable and Conscientious, as a result of presenting a more authentic yet also negative and taboo self. These differences seem to arise from differences in audience, allowing for vastly different self-presentations. Results have important implications for the theory and design of social media.
"
Inhaling and Exhaling: How Technologies Can Perceptually Extend our Breath Awareness,https://dl.acm.org/doi/10.1145/3313831.3376183,"
Attending to breath is a self-awareness practice that exists within many contemplative and reflective traditions and is recognized for its benefits to well-being. Our current technological landscape embraces a large body of systems that utilize breath data in order to foster self-awareness. This paper seeks to deepen our understanding of the design space of systems that perceptually extend breath awareness. Our contribution is twofold: (1) our analysis reveals how the underlying theoretical frameworks shape the system design and its evaluation, and (2) how system design features support perceptual extension of breath awareness. We review and critically analyze 31 breath-based interactive systems. We identify 4 theoretical frameworks and 3 design strategies for interactive systems that perceptually extend breath awareness. We reflect upon this design space from both a theoretical and system design perspective, and propose future design directions for developing systems that ""listen to"" breath and perceptually extend it. We critically analyzed 31 breath-based interactive systems and unveiled four theoretical frameworks that shape design goals and decisions through their differing epistemological commitments. Our goal was to deepen the understanding of design approaches employed to perceptually extend breath awareness. To that end, we discussed three design features of these systems that help users in guiding and sustaining attention to their breathing, and how these features support the theoretical frameworks underlying the motivation of the systems. We conclude the paper with two takeaway points regarding design of systems that perceptually extend breath.
"
"Reading with the Tongue: Individual Differences Affect the Perception of Ambiguous
                     Stimuli with the BrainPort",https://dl.acm.org/doi/10.1145/3313831.3376184,"
There is an increasing interest in non-visual interfaces for HCI to take advantage of the information processing capability of the other sensory modalities. The BrainPort is a vision-to-tactile sensory substitution device that conveys information through electro-stimulation on the tongue. As the tongue is a horizontal surface, it makes for an interesting platform to study the brain's representation of space. But which way is up on the tongue? We provided participants with perceptually ambiguous stimuli and measured how often different perspectives were adopted; furthermore, whether camera orientation and gender had an effect. Additionally, we examined whether personality (trait extraversion and openness) could predict the perspective taken. We found that self-centered perspectives were predominantly adopted, and that trait openness may predict perspective. This research demonstrates how individual differences can affect the usability of sensory substitution devices, and highlights the need for flexible and customisable interfaces. The research of sensory substitution has much to offer the field of HCI, in the form of maximizing information transfer through non-visual displays. Our research into perspectivetaking, using the tongue as an interface receptor, shows that when considering tactile displays, it is crucial to strive for the most customizable displays as possible. Factors that contribute to making a device as intuitive as possible can range through personal, interpersonal, and spatial; we tested gender, trait openness and extraversion, and camera orientation. We saw that openness may have played a small role in influencing the adopted perspective, but not to a sufficient enough degree to explain the observed variation within the sample. Making devices highly customizable would allow for individual differences within a user population, regardless of influencing factors. Specifically, regarding the BrainPort, a simple software update could improve the accessibility for users, particularly in the initial stages of acquiring the device.
"
"Bottom-Up Organizing with Tools from On High: Understanding the Data Practices of
                     Labor Organizers",https://dl.acm.org/doi/10.1145/3313831.3376185,"
This paper provides insight into the use of data tools in the American labor movement by analyzing the practices of staff employed by unions to organize alongside union members. We interviewed 23 field-level staff organizers about how they use data tools to evaluate membership. We find that organizers work around and outside of these tools to develop access to data for union members and calibrate data representations to meet local needs. Organizers mediate between local and central versions of the data, and draw on their contextual knowledge to challenge campaign strategy. We argue that networked data tools can compound field organizers' lack of discretion, making it more difficult for unions to assess and act on the will of union membership. We show how the use of networked data tools can lead to less accurate data, and discuss how bottom-up approaches to data gathering can support more accurate membership assessments. In this paper we describe how networked data management systems impact the on-the-ground experiences of organizers and what work they must do to actually make the data useful for the union and their own work as organizers. We have described how field organizers negotiate differential levels of data access and calibrate representations of the data to different levels of the union’s organization. We have also shown how organizer’s ability to do these things is potentially impacted by the use of networked data tools, because the tools introduce implementation lag and change the way knowledge is exchanged within the organization, limiting the unique knowledge the field level organizer can leverage in making recommendations. We discuss how the use of these tools constrains the organizer’s ability to efficiently share membership data with activists, potentially hindering data gathering and member activist leadership development. We make recommendations for improvements to the design of systems–to anticipate and support data workarounds through better frontend data migration–and to the role and distribution of technical expertise within the labor union’s organization structure.
"
Move Your Body: Engaging Museum Visitors with Human-Data Interaction,https://dl.acm.org/doi/10.1145/3313831.3376186,"
Museums have embraced embodied interaction: its novelty generates buzz and excitement among their patrons, and it has enormous educational potential. Human-Data Interaction (HDI) is a class of embodied interactions that enables people to explore large sets of data using interactive visualizations that users control with gestures and body movements. In museums, however, HDI installations have no utility if visitors do not engage with them. In this paper, we present a quasi-experimental study that investigates how different ways of representing the user (""mode type"") next-to a data visualization alters the way in which people engage with a HDI system. We consider four mode types: avatar, skeleton, camera overlay, and control. Our findings indicate that the mode type impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system. In this paper, we tackled four challenges for the design of interactive HDI installations: limiting display blindness and attracting people towards the screen; aiding visitors in guessing the gestures and body movements that control the system; keeping users engaged in the interaction; and, sustaining visitors’ attention on the data. Our results indicate that the design of the visualization and, in particular, how we represent people on the screen (mode type) impacts the number of visitors that interact with the installation, the gestures that people do, and the amount of time that visitors spend observing the data on display and interacting with the system. Future work should investigate whether mode type and interaction type also influence the way in which visitors discuss the data sets on the screen (probably by taking a more qualitative approach in terms of research design).
"
Experiential Qualities of Whispering with Voice Assistants,https://dl.acm.org/doi/10.1145/3313831.3376187,"
We present a Research through Design project that explores how whispering influences the ways people experience and interact with voice assistants. The research project includes a co-speculation workshop and the use of a design probe, which culminated in the production of a design fiction short film. Our design-led inquiry contributes with experiential qualities of whispering with voice assistants: creepiness, trust, and intimacy. Furthermore, we present how whispering opens up new dimensions of how and when voice interaction could be used. We propose that designers of whispering voice assistants should reflect on how they facilitate the experiential qualities of creepiness, trust, and intimacy, and reflect on the potential challenges whispering brings to the relation between a user and a voice assistant. In this paper, we presented a RtD project exploring whispering with voice assistants. The research project included an auto-ethnographic experiences with Amazon Alexa and Google Home, a co-speculation workshop, the use of a probe as well as a design fiction short film One. Our argument for this research is the need to better understand how whispering can change and shape how designers design voice assistants and how whispering affects the user of the voice assistant. The design fiction short film presented in this paper particularises a novel way to communicate with a voice assistant, speculating on the experiences and aesthetics of whispering and how whispering could change the human-computer relation. We contributed with dimensions of whispering, closer to instrumental ideals, and experiential qualities, closer to the aesthetics of interaction. The design fiction short film raises several open-ended questions relating to the experiential qualities, such as: What are the limits to how human-like we want our technologies to be, and how close we want to be with them? Can the trust created by an increased sense of empathy from technologies be beneficial to a user, or are we doomed to rely on technology even more in the future? What does this mean to our freedom of choice and expression? These questions are hardly resolved by this research but instead addressed for future speculations to be explored and evaluated in RtD and empirical studies.
"
